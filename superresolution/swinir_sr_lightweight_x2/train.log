22-11-05 02:20:07.726 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netE: None
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 1
      dataloader_batch_size: 16
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-05 02:20:07.761 : Number of train images: 3,550, iters: 222
22-11-05 02:21:07.351 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netE: None
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 1
      dataloader_batch_size: 16
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-05 02:21:07.385 : Number of train images: 3,550, iters: 222
22-11-05 02:21:10.452 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-05 02:21:11.923 : 
 |  mean  |  min   |  max   |  std   || shape               
 |  0.003 | -0.191 |  0.192 |  0.109 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.056 | -0.189 |  0.192 |  0.098 | torch.Size([30]) || conv_first.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || patch_embed.norm.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.073 |  0.052 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.063 |  0.072 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.001 | -0.067 |  0.061 |  0.019 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.057 |  0.075 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 | -0.001 | -0.072 |  0.069 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 |  0.000 | -0.060 |  0.069 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.083 |  0.071 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.060 |  0.071 |  0.021 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.068 |  0.067 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.070 |  0.070 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.001 | -0.075 |  0.058 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.073 |  0.063 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.062 |  0.061 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.075 |  0.077 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.068 |  0.061 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.001 | -0.063 |  0.054 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -0.068 |  0.066 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.074 |  0.059 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 | -0.001 | -0.063 |  0.073 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 | -0.001 | -0.071 |  0.087 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.000 | -0.066 |  0.070 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 | -0.000 | -0.082 |  0.083 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.050 |  0.065 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 | -0.001 | -0.064 |  0.062 |  0.019 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.070 |  0.060 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.080 |  0.057 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 | -0.001 | -0.072 |  0.077 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.001 | -0.063 |  0.066 |  0.021 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 | -0.001 | -0.058 |  0.069 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.058 |  0.076 |  0.019 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.001 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.004 | -0.059 |  0.059 |  0.034 | torch.Size([30]) || layers.0.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 |  0.001 | -0.063 |  0.077 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.065 |  0.077 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.059 |  0.057 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.066 |  0.069 |  0.021 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 | -0.000 | -0.060 |  0.064 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.060 |  0.073 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.087 |  0.062 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 |  0.000 | -0.076 |  0.064 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.069 |  0.077 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.000 | -0.062 |  0.076 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 |  0.001 | -0.060 |  0.066 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.074 |  0.069 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.064 |  0.061 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.064 |  0.063 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.065 |  0.065 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 |  0.000 | -0.073 |  0.066 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 | -0.001 | -0.074 |  0.062 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 |  0.000 | -0.059 |  0.061 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.064 |  0.054 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.083 |  0.063 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 |  0.001 | -0.073 |  0.081 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.064 |  0.061 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 |  0.001 | -0.066 |  0.078 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.080 |  0.058 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.072 |  0.063 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.063 |  0.064 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.078 |  0.063 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 | -0.001 | -0.061 |  0.067 |  0.019 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.071 |  0.070 |  0.021 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.062 |  0.070 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 | -0.001 | -0.060 |  0.058 |  0.036 | torch.Size([30]) || layers.1.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || norm.bias
 | -0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 | -0.002 | -0.060 |  0.049 |  0.036 | torch.Size([30]) || conv_after_body.bias
 |  0.000 | -0.061 |  0.061 |  0.035 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.006 | -0.058 |  0.057 |  0.037 | torch.Size([12]) || upsample.0.bias

22-11-05 02:29:15.929 : <epoch:  0, iter:     200, lr:2.000e-04> G_loss: 3.924e-02 
22-11-05 02:29:42.368 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netE: None
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 1
      dataloader_batch_size: 32
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-05 02:29:42.408 : Number of train images: 3,550, iters: 111
22-11-05 02:29:43.812 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-05 02:30:08.520 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.002 | -0.192 |  0.192 |  0.112 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 | -0.005 | -0.187 |  0.174 |  0.111 | torch.Size([30]) || conv_first.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || patch_embed.norm.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.085 |  0.073 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.000 | -0.077 |  0.070 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 | -0.002 | -0.069 |  0.070 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.066 |  0.066 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 | -0.001 | -0.061 |  0.068 |  0.019 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 |  0.001 | -0.072 |  0.068 |  0.021 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 |  0.001 | -0.093 |  0.069 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 |  0.001 | -0.068 |  0.062 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.076 |  0.076 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.073 |  0.070 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.000 | -0.061 |  0.062 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.076 |  0.064 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.000 | -0.066 |  0.060 |  0.019 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.061 |  0.071 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.063 |  0.071 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 |  0.000 | -0.062 |  0.059 |  0.019 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -0.081 |  0.082 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 |  0.000 | -0.070 |  0.066 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.060 |  0.066 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.106 |  0.082 |  0.021 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.000 | -0.061 |  0.057 |  0.019 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.067 |  0.088 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 |  0.000 | -0.073 |  0.066 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.060 |  0.063 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.060 |  0.082 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.058 |  0.061 |  0.019 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.068 |  0.064 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.063 |  0.063 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 | -0.001 | -0.057 |  0.066 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.067 |  0.065 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 |  0.002 | -0.054 |  0.059 |  0.039 | torch.Size([30]) || layers.0.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.072 |  0.069 |  0.021 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 |  0.001 | -0.062 |  0.078 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.064 |  0.061 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 | -0.001 | -0.062 |  0.066 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.059 |  0.076 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.001 | -0.073 |  0.060 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 |  0.001 | -0.071 |  0.070 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 |  0.000 | -0.063 |  0.063 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 | -0.001 | -0.072 |  0.073 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 |  0.000 | -0.064 |  0.068 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.001 | -0.068 |  0.068 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.071 |  0.063 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 | -0.000 | -0.059 |  0.064 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.073 |  0.071 |  0.021 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 |  0.000 | -0.069 |  0.069 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 |  0.000 | -0.057 |  0.069 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.065 |  0.081 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.087 |  0.054 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 | -0.000 | -0.070 |  0.064 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 | -0.000 | -0.074 |  0.074 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.000 | -0.071 |  0.065 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.001 | -0.062 |  0.071 |  0.019 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 |  0.002 | -0.065 |  0.069 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.060 |  0.072 |  0.019 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.064 |  0.069 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.067 |  0.064 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.073 |  0.064 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.000 | -0.057 |  0.062 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.073 |  0.071 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.000 | -0.081 |  0.065 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 | -0.007 | -0.058 |  0.055 |  0.031 | torch.Size([30]) || layers.1.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || norm.bias
 | -0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 | -0.005 | -0.061 |  0.061 |  0.037 | torch.Size([30]) || conv_after_body.bias
 | -0.000 | -0.061 |  0.061 |  0.035 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 |  0.027 | -0.027 |  0.055 |  0.023 | torch.Size([12]) || upsample.0.bias

22-11-05 02:31:37.078 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: None
    pretrained_netE: None
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: None
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 4
      dataloader_batch_size: 32
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-05 02:31:37.112 : Number of train images: 3,550, iters: 111
22-11-05 02:31:38.372 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-05 02:31:38.423 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.001 | -0.192 |  0.192 |  0.108 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.035 | -0.157 |  0.187 |  0.105 | torch.Size([30]) || conv_first.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || patch_embed.norm.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 |  0.000 | -0.072 |  0.060 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.000 | -0.076 |  0.072 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 | -0.000 | -0.060 |  0.058 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 | -0.001 | -0.073 |  0.069 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 | -0.001 | -0.082 |  0.061 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.000 | -0.067 |  0.059 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 |  0.000 | -0.068 |  0.074 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.068 |  0.068 |  0.021 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.058 |  0.069 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.062 |  0.073 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.000 | -0.058 |  0.069 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 |  0.001 | -0.066 |  0.064 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.057 |  0.068 |  0.021 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.067 |  0.061 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.077 |  0.083 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.000 | -0.061 |  0.060 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.076 |  0.068 |  0.020 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.057 |  0.065 |  0.019 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.069 |  0.069 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.060 |  0.060 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 |  0.000 | -0.063 |  0.062 |  0.020 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.078 |  0.074 |  0.021 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 |  0.000 | -0.058 |  0.075 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.066 |  0.071 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.000 | -0.068 |  0.068 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.000 | -0.082 |  0.068 |  0.021 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 |  0.001 | -0.071 |  0.080 |  0.021 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.001 | -0.060 |  0.072 |  0.020 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.057 |  0.074 |  0.020 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.000 | -0.066 |  0.088 |  0.020 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.008 | -0.059 |  0.058 |  0.037 | torch.Size([30]) || layers.0.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.001 | -0.070 |  0.075 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.000 | -0.084 |  0.074 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 | -0.001 | -0.055 |  0.065 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.062 |  0.065 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.065 |  0.059 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 |  0.001 | -0.078 |  0.090 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.062 |  0.077 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.001 | -0.057 |  0.061 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.060 |  0.061 |  0.019 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.079 |  0.067 |  0.019 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 |  0.001 | -0.074 |  0.063 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 | -0.000 | -0.069 |  0.065 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.069 |  0.066 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 |  0.000 | -0.064 |  0.061 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.070 |  0.071 |  0.021 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.001 | -0.068 |  0.058 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 | -0.000 | -0.064 |  0.069 |  0.021 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.064 |  0.073 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 | -0.001 | -0.080 |  0.072 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 |  0.000 | -0.067 |  0.078 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.001 | -0.064 |  0.063 |  0.019 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 | -0.000 | -0.065 |  0.071 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.062 |  0.069 |  0.019 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.059 |  0.059 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.069 |  0.068 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 |  0.000 | -0.064 |  0.090 |  0.020 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 | -0.000 | -0.075 |  0.076 |  0.020 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.001 | -0.065 |  0.062 |  0.020 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.001 | -0.066 |  0.057 |  0.020 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.071 |  0.072 |  0.020 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 |  0.003 | -0.057 |  0.060 |  0.036 | torch.Size([30]) || layers.1.conv.bias
 |  1.000 |  1.000 |  1.000 |  0.000 | torch.Size([30]) || norm.weight
 |  0.000 |  0.000 |  0.000 |  0.000 | torch.Size([30]) || norm.bias
 |  0.000 | -0.061 |  0.061 |  0.035 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 |  0.005 | -0.044 |  0.058 |  0.030 | torch.Size([30]) || conv_after_body.bias
 | -0.000 | -0.061 |  0.061 |  0.035 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.007 | -0.051 |  0.045 |  0.032 | torch.Size([12]) || upsample.0.bias

22-11-05 02:37:21.175 : <epoch:  1, iter:     200, lr:2.000e-04> G_loss: 3.684e-02 
22-11-05 02:42:45.674 : <epoch:  3, iter:     400, lr:2.000e-04> G_loss: 2.826e-02 
22-11-05 02:48:10.518 : <epoch:  5, iter:     600, lr:2.000e-04> G_loss: 3.289e-02 
22-11-05 02:53:24.578 : <epoch:  7, iter:     800, lr:2.000e-04> G_loss: 2.280e-02 
22-11-05 02:58:25.270 : <epoch:  9, iter:   1,000, lr:2.000e-04> G_loss: 2.534e-02 
22-11-05 03:03:15.487 : <epoch: 10, iter:   1,200, lr:2.000e-04> G_loss: 1.906e-02 
22-11-05 03:08:14.975 : <epoch: 12, iter:   1,400, lr:2.000e-04> G_loss: 1.758e-02 
22-11-05 03:13:13.294 : <epoch: 14, iter:   1,600, lr:2.000e-04> G_loss: 1.708e-02 
22-11-05 03:18:11.762 : <epoch: 16, iter:   1,800, lr:2.000e-04> G_loss: 2.188e-02 
22-11-05 03:23:09.834 : <epoch: 18, iter:   2,000, lr:2.000e-04> G_loss: 1.673e-02 
22-11-05 03:27:56.072 : <epoch: 19, iter:   2,200, lr:2.000e-04> G_loss: 2.036e-02 
22-11-05 03:32:54.041 : <epoch: 21, iter:   2,400, lr:2.000e-04> G_loss: 1.811e-02 
22-11-05 03:37:51.665 : <epoch: 23, iter:   2,600, lr:2.000e-04> G_loss: 1.981e-02 
22-11-05 03:42:48.016 : <epoch: 25, iter:   2,800, lr:2.000e-04> G_loss: 2.433e-02 
22-11-05 03:47:44.924 : <epoch: 27, iter:   3,000, lr:2.000e-04> G_loss: 2.205e-02 
22-11-05 03:52:45.045 : <epoch: 29, iter:   3,200, lr:2.000e-04> G_loss: 2.130e-02 
22-11-05 03:57:32.593 : <epoch: 30, iter:   3,400, lr:2.000e-04> G_loss: 2.226e-02 
22-11-05 04:02:31.912 : <epoch: 32, iter:   3,600, lr:2.000e-04> G_loss: 1.755e-02 
22-11-05 04:07:31.634 : <epoch: 34, iter:   3,800, lr:2.000e-04> G_loss: 1.664e-02 
22-11-05 04:12:31.898 : <epoch: 36, iter:   4,000, lr:2.000e-04> G_loss: 1.481e-02 
22-11-05 04:17:29.605 : <epoch: 38, iter:   4,200, lr:2.000e-04> G_loss: 1.643e-02 
22-11-05 04:22:18.279 : <epoch: 39, iter:   4,400, lr:2.000e-04> G_loss: 1.554e-02 
22-11-05 04:27:14.983 : <epoch: 41, iter:   4,600, lr:2.000e-04> G_loss: 1.585e-02 
22-11-05 04:32:13.299 : <epoch: 43, iter:   4,800, lr:2.000e-04> G_loss: 2.223e-02 
22-11-05 04:37:09.807 : <epoch: 45, iter:   5,000, lr:2.000e-04> G_loss: 2.425e-02 
22-11-05 04:37:09.807 : Saving the model.
22-11-05 04:37:12.954 : ---1--> babyx2.png | 36.50dB
22-11-05 04:37:13.153 : ---2--> birdx2.png | 36.07dB
22-11-05 04:37:13.305 : ---3--> butterflyx2.png | 27.54dB
22-11-05 04:37:13.480 : ---4--> headx2.png | 31.80dB
22-11-05 04:37:13.670 : ---5--> womanx2.png | 32.33dB
22-11-05 04:37:14.051 : <epoch: 45, iter:   5,000, Average PSNR : 32.85dB

22-11-05 04:42:07.269 : <epoch: 47, iter:   5,200, lr:2.000e-04> G_loss: 2.349e-02 
22-11-05 04:47:04.626 : <epoch: 49, iter:   5,400, lr:2.000e-04> G_loss: 1.593e-02 
22-11-05 04:51:48.989 : <epoch: 50, iter:   5,600, lr:2.000e-04> G_loss: 1.368e-02 
22-11-05 04:56:44.480 : <epoch: 52, iter:   5,800, lr:2.000e-04> G_loss: 1.592e-02 
22-11-05 05:01:41.803 : <epoch: 54, iter:   6,000, lr:2.000e-04> G_loss: 2.032e-02 
22-11-05 05:06:38.311 : <epoch: 56, iter:   6,200, lr:2.000e-04> G_loss: 1.770e-02 
22-11-05 05:11:35.426 : <epoch: 58, iter:   6,400, lr:2.000e-04> G_loss: 2.200e-02 
22-11-05 05:16:23.611 : <epoch: 59, iter:   6,600, lr:2.000e-04> G_loss: 1.627e-02 
22-11-05 05:21:20.465 : <epoch: 61, iter:   6,800, lr:2.000e-04> G_loss: 1.692e-02 
22-11-05 05:26:17.072 : <epoch: 63, iter:   7,000, lr:2.000e-04> G_loss: 2.017e-02 
22-11-05 05:31:12.747 : <epoch: 65, iter:   7,200, lr:2.000e-04> G_loss: 1.882e-02 
22-11-05 05:36:10.275 : <epoch: 67, iter:   7,400, lr:2.000e-04> G_loss: 1.593e-02 
22-11-05 05:41:06.194 : <epoch: 69, iter:   7,600, lr:2.000e-04> G_loss: 1.646e-02 
22-11-05 05:45:51.162 : <epoch: 70, iter:   7,800, lr:2.000e-04> G_loss: 1.954e-02 
22-11-05 05:50:46.377 : <epoch: 72, iter:   8,000, lr:2.000e-04> G_loss: 1.996e-02 
22-11-05 05:55:42.379 : <epoch: 74, iter:   8,200, lr:2.000e-04> G_loss: 1.535e-02 
22-11-05 06:00:38.453 : <epoch: 76, iter:   8,400, lr:2.000e-04> G_loss: 1.905e-02 
22-11-05 06:05:34.796 : <epoch: 78, iter:   8,600, lr:2.000e-04> G_loss: 2.456e-02 
22-11-05 06:10:21.579 : <epoch: 79, iter:   8,800, lr:2.000e-04> G_loss: 1.891e-02 
22-11-05 06:15:18.335 : <epoch: 81, iter:   9,000, lr:2.000e-04> G_loss: 1.519e-02 
22-11-05 06:20:14.670 : <epoch: 83, iter:   9,200, lr:2.000e-04> G_loss: 1.634e-02 
22-11-05 06:25:11.569 : <epoch: 85, iter:   9,400, lr:2.000e-04> G_loss: 1.479e-02 
22-11-05 06:30:08.680 : <epoch: 87, iter:   9,600, lr:2.000e-04> G_loss: 1.360e-02 
22-11-05 06:35:05.591 : <epoch: 89, iter:   9,800, lr:2.000e-04> G_loss: 1.898e-02 
22-11-05 06:39:48.846 : <epoch: 90, iter:  10,000, lr:2.000e-04> G_loss: 2.144e-02 
22-11-05 06:39:48.846 : Saving the model.
22-11-05 06:39:52.333 : ---1--> babyx2.png | 36.68dB
22-11-05 06:39:52.511 : ---2--> birdx2.png | 36.68dB
22-11-05 06:39:52.653 : ---3--> butterflyx2.png | 27.72dB
22-11-05 06:39:52.821 : ---4--> headx2.png | 31.91dB
22-11-05 06:39:52.997 : ---5--> womanx2.png | 32.43dB
22-11-05 06:39:53.381 : <epoch: 90, iter:  10,000, Average PSNR : 33.09dB

22-11-05 06:44:44.852 : <epoch: 92, iter:  10,200, lr:2.000e-04> G_loss: 1.376e-02 
22-11-05 06:49:42.515 : <epoch: 94, iter:  10,400, lr:2.000e-04> G_loss: 2.182e-02 
22-11-05 06:54:38.021 : <epoch: 96, iter:  10,600, lr:2.000e-04> G_loss: 1.636e-02 
22-11-05 06:59:34.388 : <epoch: 98, iter:  10,800, lr:2.000e-04> G_loss: 2.111e-02 
22-11-05 07:04:21.615 : <epoch: 99, iter:  11,000, lr:2.000e-04> G_loss: 2.221e-02 
22-11-05 07:09:19.535 : <epoch:101, iter:  11,200, lr:2.000e-04> G_loss: 1.558e-02 
22-11-05 07:14:14.267 : <epoch:103, iter:  11,400, lr:2.000e-04> G_loss: 1.543e-02 
22-11-05 07:19:11.360 : <epoch:105, iter:  11,600, lr:2.000e-04> G_loss: 1.730e-02 
22-11-05 07:24:08.062 : <epoch:107, iter:  11,800, lr:2.000e-04> G_loss: 1.338e-02 
22-11-05 07:29:04.160 : <epoch:109, iter:  12,000, lr:2.000e-04> G_loss: 1.533e-02 
22-11-05 07:33:47.330 : <epoch:110, iter:  12,200, lr:2.000e-04> G_loss: 2.491e-02 
22-11-05 07:38:45.257 : <epoch:112, iter:  12,400, lr:2.000e-04> G_loss: 2.045e-02 
22-11-05 07:43:39.971 : <epoch:114, iter:  12,600, lr:2.000e-04> G_loss: 1.648e-02 
22-11-05 07:48:37.043 : <epoch:116, iter:  12,800, lr:2.000e-04> G_loss: 1.116e-02 
22-11-05 07:53:33.545 : <epoch:118, iter:  13,000, lr:2.000e-04> G_loss: 1.490e-02 
22-11-05 07:58:21.168 : <epoch:119, iter:  13,200, lr:2.000e-04> G_loss: 1.855e-02 
22-11-05 08:03:18.476 : <epoch:121, iter:  13,400, lr:2.000e-04> G_loss: 1.543e-02 
22-11-05 08:08:14.615 : <epoch:123, iter:  13,600, lr:2.000e-04> G_loss: 1.620e-02 
22-11-05 08:13:10.878 : <epoch:125, iter:  13,800, lr:2.000e-04> G_loss: 1.798e-02 
22-11-05 08:18:07.830 : <epoch:127, iter:  14,000, lr:2.000e-04> G_loss: 1.865e-02 
22-11-05 08:23:04.505 : <epoch:129, iter:  14,200, lr:2.000e-04> G_loss: 2.021e-02 
22-11-05 08:27:47.465 : <epoch:130, iter:  14,400, lr:2.000e-04> G_loss: 1.925e-02 
22-11-05 08:32:43.527 : <epoch:132, iter:  14,600, lr:2.000e-04> G_loss: 1.652e-02 
22-11-05 08:37:39.484 : <epoch:134, iter:  14,800, lr:2.000e-04> G_loss: 1.525e-02 
22-11-05 08:42:35.244 : <epoch:136, iter:  15,000, lr:2.000e-04> G_loss: 1.906e-02 
22-11-05 08:42:35.244 : Saving the model.
22-11-05 08:42:38.335 : ---1--> babyx2.png | 36.81dB
22-11-05 08:42:38.517 : ---2--> birdx2.png | 37.17dB
22-11-05 08:42:38.673 : ---3--> butterflyx2.png | 28.98dB
22-11-05 08:42:38.856 : ---4--> headx2.png | 31.98dB
22-11-05 08:42:39.033 : ---5--> womanx2.png | 33.24dB
22-11-05 08:42:39.329 : <epoch:136, iter:  15,000, Average PSNR : 33.64dB

22-11-05 08:47:31.940 : <epoch:138, iter:  15,200, lr:2.000e-04> G_loss: 1.632e-02 
22-11-05 08:52:17.650 : <epoch:139, iter:  15,400, lr:2.000e-04> G_loss: 2.084e-02 
22-11-05 08:57:15.901 : <epoch:141, iter:  15,600, lr:2.000e-04> G_loss: 1.585e-02 
22-11-05 09:02:13.199 : <epoch:143, iter:  15,800, lr:2.000e-04> G_loss: 1.601e-02 
22-11-05 09:07:10.216 : <epoch:145, iter:  16,000, lr:2.000e-04> G_loss: 1.533e-02 
22-11-05 09:12:06.979 : <epoch:147, iter:  16,200, lr:2.000e-04> G_loss: 1.706e-02 
22-11-05 09:17:03.917 : <epoch:149, iter:  16,400, lr:2.000e-04> G_loss: 2.229e-02 
22-11-05 09:21:46.693 : <epoch:150, iter:  16,600, lr:2.000e-04> G_loss: 1.063e-02 
22-11-05 09:26:45.007 : <epoch:152, iter:  16,800, lr:2.000e-04> G_loss: 1.823e-02 
22-11-05 09:33:24.712 : <epoch:154, iter:  17,000, lr:2.000e-04> G_loss: 1.018e-02 
22-11-05 09:38:47.978 : <epoch:156, iter:  17,200, lr:2.000e-04> G_loss: 1.513e-02 
22-11-05 09:43:56.647 : <epoch:158, iter:  17,400, lr:2.000e-04> G_loss: 1.796e-02 
22-11-05 09:49:15.468 : <epoch:159, iter:  17,600, lr:2.000e-04> G_loss: 1.557e-02 
22-11-05 09:54:44.210 : <epoch:161, iter:  17,800, lr:2.000e-04> G_loss: 2.112e-02 
22-11-05 10:00:10.925 : <epoch:163, iter:  18,000, lr:2.000e-04> G_loss: 1.613e-02 
22-11-05 10:05:39.444 : <epoch:165, iter:  18,200, lr:2.000e-04> G_loss: 1.775e-02 
22-11-05 10:12:48.205 : <epoch:167, iter:  18,400, lr:2.000e-04> G_loss: 1.904e-02 
22-11-05 10:18:12.115 : <epoch:169, iter:  18,600, lr:2.000e-04> G_loss: 1.656e-02 
22-11-05 10:23:21.876 : <epoch:170, iter:  18,800, lr:2.000e-04> G_loss: 1.211e-02 
22-11-05 10:28:45.125 : <epoch:172, iter:  19,000, lr:2.000e-04> G_loss: 1.951e-02 
22-11-05 10:34:10.736 : <epoch:174, iter:  19,200, lr:2.000e-04> G_loss: 2.015e-02 
22-11-05 10:39:35.961 : <epoch:176, iter:  19,400, lr:2.000e-04> G_loss: 1.504e-02 
22-11-05 10:45:09.453 : <epoch:178, iter:  19,600, lr:2.000e-04> G_loss: 1.644e-02 
22-11-05 10:50:21.418 : <epoch:179, iter:  19,800, lr:2.000e-04> G_loss: 1.375e-02 
22-11-05 10:55:51.900 : <epoch:181, iter:  20,000, lr:2.000e-04> G_loss: 1.184e-02 
22-11-05 10:55:51.900 : Saving the model.
22-11-05 10:55:55.744 : ---1--> babyx2.png | 36.95dB
22-11-05 10:55:55.949 : ---2--> birdx2.png | 38.09dB
22-11-05 10:55:56.106 : ---3--> butterflyx2.png | 30.25dB
22-11-05 10:55:56.283 : ---4--> headx2.png | 32.00dB
22-11-05 10:55:56.453 : ---5--> womanx2.png | 33.98dB
22-11-05 10:55:56.822 : <epoch:181, iter:  20,000, Average PSNR : 34.25dB

22-11-05 11:01:10.733 : <epoch:183, iter:  20,200, lr:2.000e-04> G_loss: 1.814e-02 
22-11-05 11:06:36.031 : <epoch:185, iter:  20,400, lr:2.000e-04> G_loss: 2.466e-02 
22-11-05 11:11:37.100 : <epoch:187, iter:  20,600, lr:2.000e-04> G_loss: 1.591e-02 
22-11-05 11:16:38.252 : <epoch:189, iter:  20,800, lr:2.000e-04> G_loss: 1.011e-02 
22-11-05 11:21:28.451 : <epoch:190, iter:  21,000, lr:2.000e-04> G_loss: 1.415e-02 
22-11-05 11:26:38.517 : <epoch:192, iter:  21,200, lr:2.000e-04> G_loss: 1.577e-02 
22-11-05 11:36:48.830 : <epoch:194, iter:  21,400, lr:2.000e-04> G_loss: 1.489e-02 
22-11-05 11:41:50.706 : <epoch:196, iter:  21,600, lr:2.000e-04> G_loss: 1.693e-02 
22-11-05 11:47:09.421 : <epoch:198, iter:  21,800, lr:2.000e-04> G_loss: 1.905e-02 
22-11-05 11:52:13.070 : <epoch:199, iter:  22,000, lr:2.000e-04> G_loss: 1.511e-02 
22-11-05 11:57:15.398 : <epoch:201, iter:  22,200, lr:2.000e-04> G_loss: 1.591e-02 
22-11-05 12:02:18.522 : <epoch:203, iter:  22,400, lr:2.000e-04> G_loss: 1.976e-02 
22-11-05 12:07:20.575 : <epoch:205, iter:  22,600, lr:2.000e-04> G_loss: 1.517e-02 
22-11-05 12:12:23.089 : <epoch:207, iter:  22,800, lr:2.000e-04> G_loss: 1.301e-02 
22-11-05 12:17:25.211 : <epoch:209, iter:  23,000, lr:2.000e-04> G_loss: 1.498e-02 
22-11-05 12:22:10.152 : <epoch:210, iter:  23,200, lr:2.000e-04> G_loss: 1.398e-02 
22-11-05 12:27:09.318 : <epoch:212, iter:  23,400, lr:2.000e-04> G_loss: 1.855e-02 
22-11-05 12:32:08.393 : <epoch:214, iter:  23,600, lr:2.000e-04> G_loss: 1.418e-02 
22-11-05 12:37:14.098 : <epoch:216, iter:  23,800, lr:2.000e-04> G_loss: 1.940e-02 
22-11-05 12:42:31.180 : <epoch:218, iter:  24,000, lr:2.000e-04> G_loss: 2.100e-02 
22-11-05 12:47:31.476 : <epoch:219, iter:  24,200, lr:2.000e-04> G_loss: 1.631e-02 
22-11-05 12:52:32.121 : <epoch:221, iter:  24,400, lr:2.000e-04> G_loss: 1.835e-02 
22-11-05 12:57:31.669 : <epoch:223, iter:  24,600, lr:2.000e-04> G_loss: 1.498e-02 
22-11-05 13:02:30.749 : <epoch:225, iter:  24,800, lr:2.000e-04> G_loss: 1.390e-02 
22-11-05 13:29:51.659 : <epoch:227, iter:  25,000, lr:2.000e-04> G_loss: 1.383e-02 
22-11-05 13:29:51.659 : Saving the model.
22-11-05 13:29:54.858 : ---1--> babyx2.png | 36.93dB
22-11-05 13:29:55.033 : ---2--> birdx2.png | 38.05dB
22-11-05 13:29:55.174 : ---3--> butterflyx2.png | 30.84dB
22-11-05 13:29:55.356 : ---4--> headx2.png | 32.00dB
22-11-05 13:29:55.530 : ---5--> womanx2.png | 34.22dB
22-11-05 13:29:55.828 : <epoch:227, iter:  25,000, Average PSNR : 34.41dB

22-11-05 13:34:51.544 : <epoch:229, iter:  25,200, lr:2.000e-04> G_loss: 1.733e-02 
22-11-05 13:42:03.767 : <epoch:230, iter:  25,400, lr:2.000e-04> G_loss: 1.522e-02 
22-11-08 13:29:34.553 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution\swinir_sr_lightweight_x2\models\25000_G.pth
    pretrained_netE: superresolution\swinir_sr_lightweight_x2\models\25000_E.pth
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: superresolution\swinir_sr_lightweight_x2\models\25000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 4
      dataloader_batch_size: 32
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-08 13:29:34.588 : Number of train images: 3,550, iters: 111
22-11-08 13:31:14.810 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution\swinir_sr_lightweight_x2\models\25000_G.pth
    pretrained_netE: superresolution\swinir_sr_lightweight_x2\models\25000_E.pth
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: superresolution\swinir_sr_lightweight_x2\models\25000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 4
      dataloader_batch_size: 32
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-08 13:31:14.845 : Number of train images: 3,550, iters: 111
22-11-08 13:31:17.236 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-08 13:31:17.295 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.003 | -0.240 |  0.245 |  0.110 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.038 | -0.187 |  0.226 |  0.120 | torch.Size([30]) || conv_first.bias
 |  1.001 |  0.948 |  1.096 |  0.029 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 | -0.024 |  0.036 |  0.015 | torch.Size([30]) || patch_embed.norm.bias
 |  1.061 |  1.012 |  1.196 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 | -0.001 | -0.022 |  0.028 |  0.012 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 | -0.077 | -1.031 |  1.767 |  0.279 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.001 | -0.631 |  0.742 |  0.133 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.007 | -0.167 |  0.243 |  0.055 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.213 |  0.097 |  0.030 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.030 |  0.034 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.065 |  1.014 |  1.157 |  0.042 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 | -0.004 | -0.026 |  0.029 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.282 |  0.174 |  0.045 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.012 | -0.025 |  0.045 |  0.015 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.209 |  0.203 |  0.038 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 | -0.000 | -0.028 |  0.034 |  0.016 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.087 |  1.000 |  1.251 |  0.054 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.030 |  0.042 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.122 | -1.551 |  2.576 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 | -0.001 | -0.744 |  0.759 |  0.171 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 | -0.006 | -0.294 |  0.266 |  0.082 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.001 | -0.265 |  0.193 |  0.035 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 | -0.020 |  0.031 |  0.010 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.060 |  0.988 |  1.187 |  0.045 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 | -0.022 |  0.030 |  0.015 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.236 |  0.235 |  0.044 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.005 | -0.020 |  0.038 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.228 |  0.173 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 | -0.019 |  0.033 |  0.011 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.160 |  1.045 |  1.328 |  0.076 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.042 |  0.056 |  0.022 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.206 | -1.663 |  2.224 |  0.396 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.781 |  0.872 |  0.187 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 | -0.004 | -0.172 |  0.148 |  0.050 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.002 | -0.218 |  0.353 |  0.047 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.014 |  0.025 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.062 |  1.009 |  1.144 |  0.038 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.001 | -0.033 |  0.045 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.288 |  0.185 |  0.043 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.005 | -0.028 |  0.045 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.286 |  0.217 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 | -0.017 |  0.025 |  0.009 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.141 |  1.008 |  1.416 |  0.081 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.002 | -0.032 |  0.057 |  0.019 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.150 | -1.948 |  2.200 |  0.350 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -1.201 |  0.883 |  0.174 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 | -0.006 | -0.175 |  0.113 |  0.044 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.336 |  0.373 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 | -0.000 | -0.009 |  0.022 |  0.006 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.047 |  0.998 |  1.132 |  0.037 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 | -0.004 | -0.036 |  0.040 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.001 | -0.190 |  0.241 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 | -0.001 | -0.034 |  0.021 |  0.012 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.172 |  0.181 |  0.033 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.024 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.168 |  1.029 |  1.347 |  0.082 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 | -0.002 | -0.063 |  0.079 |  0.028 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.160 | -1.015 |  1.922 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.003 | -0.863 |  0.708 |  0.166 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 | -0.003 | -0.127 |  0.087 |  0.035 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.409 |  0.364 |  0.055 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.010 |  0.018 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.048 |  0.985 |  1.145 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.001 | -0.036 |  0.044 |  0.021 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.218 |  0.168 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.004 | -0.022 |  0.019 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.146 |  0.172 |  0.032 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.015 |  0.023 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.108 |  0.936 |  1.483 |  0.097 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 | -0.003 | -0.045 |  0.073 |  0.029 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.093 | -1.084 |  2.083 |  0.254 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 |  0.001 | -1.182 |  0.948 |  0.172 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 | -0.006 | -0.154 |  0.095 |  0.038 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.002 | -0.276 |  0.330 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.001 | -0.010 |  0.017 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.045 |  0.968 |  1.158 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 | -0.003 | -0.063 |  0.050 |  0.025 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.155 |  0.218 |  0.036 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.020 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.001 | -0.129 |  0.146 |  0.029 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.013 |  0.021 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.155 |  0.242 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.009 | -0.085 |  0.064 |  0.038 | torch.Size([30]) || layers.0.conv.bias
 |  1.025 |  0.964 |  1.204 |  0.047 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.002 | -0.032 |  0.046 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.019 | -0.788 |  1.875 |  0.158 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.001 | -0.665 |  0.603 |  0.127 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.002 | -0.152 |  0.156 |  0.052 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.113 |  0.161 |  0.028 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.012 |  0.015 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.036 |  0.983 |  1.294 |  0.060 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.003 | -0.036 |  0.038 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.186 |  0.273 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.001 | -0.027 |  0.026 |  0.013 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.001 | -0.203 |  0.161 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.001 | -0.016 |  0.013 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.041 |  0.972 |  1.253 |  0.059 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.036 |  0.042 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.023 | -0.661 |  2.265 |  0.175 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.750 |  0.763 |  0.169 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 | -0.008 | -0.293 |  0.270 |  0.077 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.121 |  0.120 |  0.029 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.001 | -0.011 |  0.018 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.047 |  0.979 |  1.276 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.001 | -0.045 |  0.055 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.232 |  0.193 |  0.037 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.001 | -0.029 |  0.025 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.163 |  0.198 |  0.033 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.001 | -0.014 |  0.016 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.070 |  1.001 |  1.302 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.040 |  0.021 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.043 | -0.950 |  2.164 |  0.207 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.822 |  0.914 |  0.150 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.005 | -0.177 |  0.202 |  0.063 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.183 |  0.158 |  0.030 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.010 |  0.015 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.039 |  0.957 |  1.251 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.003 | -0.033 |  0.059 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.275 |  0.134 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.001 | -0.023 |  0.029 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.001 | -0.183 |  0.133 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 | -0.000 | -0.014 |  0.010 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.045 |  0.992 |  1.201 |  0.057 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 | -0.001 | -0.035 |  0.024 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.027 | -1.357 |  1.919 |  0.218 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.819 |  1.021 |  0.167 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.004 | -0.197 |  0.209 |  0.079 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.131 |  0.139 |  0.031 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 | -0.015 |  0.011 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.051 |  0.980 |  1.268 |  0.073 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 | -0.002 | -0.042 |  0.034 |  0.022 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.204 |  0.392 |  0.039 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.002 | -0.016 |  0.027 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.115 |  0.175 |  0.032 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.013 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.068 |  0.850 |  1.515 |  0.122 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 | -0.003 | -0.034 |  0.022 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.064 | -1.056 |  1.562 |  0.240 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.734 |  0.800 |  0.160 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 | -0.005 | -0.213 |  0.218 |  0.061 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.208 |  0.163 |  0.034 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.011 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.042 |  0.969 |  1.276 |  0.064 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.002 | -0.044 |  0.037 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.173 |  0.335 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.003 | -0.021 |  0.026 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.112 |  0.160 |  0.029 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.014 |  0.012 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.103 |  0.981 |  1.370 |  0.107 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.002 | -0.036 |  0.039 |  0.020 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.065 | -1.210 |  2.978 |  0.243 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 |  0.002 | -0.905 |  0.866 |  0.182 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.001 | -0.248 |  0.198 |  0.067 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.002 | -0.217 |  0.194 |  0.039 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 | -0.010 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.043 |  0.979 |  1.275 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.004 | -0.037 |  0.047 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.194 |  0.173 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.021 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.132 |  0.205 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.012 |  0.012 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.179 |  0.178 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 |  0.001 | -0.054 |  0.073 |  0.035 | torch.Size([30]) || layers.1.conv.bias
 |  0.990 |  0.872 |  1.330 |  0.079 | torch.Size([30]) || norm.weight
 | -0.000 | -0.120 |  0.097 |  0.039 | torch.Size([30]) || norm.bias
 |  0.000 | -0.215 |  0.229 |  0.039 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 |  0.005 | -0.045 |  0.051 |  0.031 | torch.Size([30]) || conv_after_body.bias
 | -0.001 | -0.156 |  0.230 |  0.036 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.004 | -0.039 |  0.034 |  0.024 | torch.Size([12]) || upsample.0.bias

22-11-08 13:32:37.988 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution\swinir_sr_lightweight_x2\models\25000_G.pth
    pretrained_netE: superresolution\swinir_sr_lightweight_x2\models\25000_E.pth
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: superresolution\swinir_sr_lightweight_x2\models\25000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 4
      dataloader_batch_size: 32
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-08 13:32:38.021 : Number of train images: 3,550, iters: 111
22-11-08 13:32:39.436 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-08 13:32:39.488 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.003 | -0.240 |  0.245 |  0.110 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.038 | -0.187 |  0.226 |  0.120 | torch.Size([30]) || conv_first.bias
 |  1.001 |  0.948 |  1.096 |  0.029 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 | -0.024 |  0.036 |  0.015 | torch.Size([30]) || patch_embed.norm.bias
 |  1.061 |  1.012 |  1.196 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 | -0.001 | -0.022 |  0.028 |  0.012 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 | -0.077 | -1.031 |  1.767 |  0.279 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.001 | -0.631 |  0.742 |  0.133 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.007 | -0.167 |  0.243 |  0.055 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.213 |  0.097 |  0.030 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.030 |  0.034 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.065 |  1.014 |  1.157 |  0.042 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 | -0.004 | -0.026 |  0.029 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.282 |  0.174 |  0.045 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.012 | -0.025 |  0.045 |  0.015 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.209 |  0.203 |  0.038 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 | -0.000 | -0.028 |  0.034 |  0.016 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.087 |  1.000 |  1.251 |  0.054 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.030 |  0.042 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.122 | -1.551 |  2.576 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 | -0.001 | -0.744 |  0.759 |  0.171 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 | -0.006 | -0.294 |  0.266 |  0.082 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.001 | -0.265 |  0.193 |  0.035 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 | -0.020 |  0.031 |  0.010 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.060 |  0.988 |  1.187 |  0.045 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 | -0.022 |  0.030 |  0.015 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.236 |  0.235 |  0.044 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.005 | -0.020 |  0.038 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.228 |  0.173 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 | -0.019 |  0.033 |  0.011 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.160 |  1.045 |  1.328 |  0.076 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.042 |  0.056 |  0.022 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.206 | -1.663 |  2.224 |  0.396 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.781 |  0.872 |  0.187 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 | -0.004 | -0.172 |  0.148 |  0.050 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.002 | -0.218 |  0.353 |  0.047 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.014 |  0.025 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.062 |  1.009 |  1.144 |  0.038 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.001 | -0.033 |  0.045 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.288 |  0.185 |  0.043 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.005 | -0.028 |  0.045 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.286 |  0.217 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 | -0.017 |  0.025 |  0.009 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.141 |  1.008 |  1.416 |  0.081 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.002 | -0.032 |  0.057 |  0.019 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.150 | -1.948 |  2.200 |  0.350 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -1.201 |  0.883 |  0.174 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 | -0.006 | -0.175 |  0.113 |  0.044 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.336 |  0.373 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 | -0.000 | -0.009 |  0.022 |  0.006 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.047 |  0.998 |  1.132 |  0.037 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 | -0.004 | -0.036 |  0.040 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.001 | -0.190 |  0.241 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 | -0.001 | -0.034 |  0.021 |  0.012 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.172 |  0.181 |  0.033 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.024 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.168 |  1.029 |  1.347 |  0.082 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 | -0.002 | -0.063 |  0.079 |  0.028 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.160 | -1.015 |  1.922 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.003 | -0.863 |  0.708 |  0.166 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 | -0.003 | -0.127 |  0.087 |  0.035 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.409 |  0.364 |  0.055 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.010 |  0.018 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.048 |  0.985 |  1.145 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.001 | -0.036 |  0.044 |  0.021 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.218 |  0.168 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.004 | -0.022 |  0.019 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.146 |  0.172 |  0.032 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.015 |  0.023 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.108 |  0.936 |  1.483 |  0.097 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 | -0.003 | -0.045 |  0.073 |  0.029 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.093 | -1.084 |  2.083 |  0.254 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 |  0.001 | -1.182 |  0.948 |  0.172 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 | -0.006 | -0.154 |  0.095 |  0.038 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.002 | -0.276 |  0.330 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.001 | -0.010 |  0.017 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.045 |  0.968 |  1.158 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 | -0.003 | -0.063 |  0.050 |  0.025 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.155 |  0.218 |  0.036 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.020 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.001 | -0.129 |  0.146 |  0.029 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.013 |  0.021 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.155 |  0.242 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.009 | -0.085 |  0.064 |  0.038 | torch.Size([30]) || layers.0.conv.bias
 |  1.025 |  0.964 |  1.204 |  0.047 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.002 | -0.032 |  0.046 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.019 | -0.788 |  1.875 |  0.158 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.001 | -0.665 |  0.603 |  0.127 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.002 | -0.152 |  0.156 |  0.052 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.113 |  0.161 |  0.028 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.012 |  0.015 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.036 |  0.983 |  1.294 |  0.060 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.003 | -0.036 |  0.038 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.186 |  0.273 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.001 | -0.027 |  0.026 |  0.013 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.001 | -0.203 |  0.161 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.001 | -0.016 |  0.013 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.041 |  0.972 |  1.253 |  0.059 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.036 |  0.042 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.023 | -0.661 |  2.265 |  0.175 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.750 |  0.763 |  0.169 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 | -0.008 | -0.293 |  0.270 |  0.077 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.121 |  0.120 |  0.029 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.001 | -0.011 |  0.018 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.047 |  0.979 |  1.276 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.001 | -0.045 |  0.055 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.232 |  0.193 |  0.037 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.001 | -0.029 |  0.025 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.163 |  0.198 |  0.033 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.001 | -0.014 |  0.016 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.070 |  1.001 |  1.302 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.040 |  0.021 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.043 | -0.950 |  2.164 |  0.207 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.822 |  0.914 |  0.150 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.005 | -0.177 |  0.202 |  0.063 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.183 |  0.158 |  0.030 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.010 |  0.015 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.039 |  0.957 |  1.251 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.003 | -0.033 |  0.059 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.275 |  0.134 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.001 | -0.023 |  0.029 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.001 | -0.183 |  0.133 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 | -0.000 | -0.014 |  0.010 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.045 |  0.992 |  1.201 |  0.057 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 | -0.001 | -0.035 |  0.024 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.027 | -1.357 |  1.919 |  0.218 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.819 |  1.021 |  0.167 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.004 | -0.197 |  0.209 |  0.079 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.131 |  0.139 |  0.031 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 | -0.015 |  0.011 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.051 |  0.980 |  1.268 |  0.073 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 | -0.002 | -0.042 |  0.034 |  0.022 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.204 |  0.392 |  0.039 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.002 | -0.016 |  0.027 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.115 |  0.175 |  0.032 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.013 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.068 |  0.850 |  1.515 |  0.122 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 | -0.003 | -0.034 |  0.022 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.064 | -1.056 |  1.562 |  0.240 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.734 |  0.800 |  0.160 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 | -0.005 | -0.213 |  0.218 |  0.061 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.208 |  0.163 |  0.034 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.011 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.042 |  0.969 |  1.276 |  0.064 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.002 | -0.044 |  0.037 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.173 |  0.335 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.003 | -0.021 |  0.026 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.112 |  0.160 |  0.029 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.014 |  0.012 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.103 |  0.981 |  1.370 |  0.107 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.002 | -0.036 |  0.039 |  0.020 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.065 | -1.210 |  2.978 |  0.243 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 |  0.002 | -0.905 |  0.866 |  0.182 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.001 | -0.248 |  0.198 |  0.067 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.002 | -0.217 |  0.194 |  0.039 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 | -0.010 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.043 |  0.979 |  1.275 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.004 | -0.037 |  0.047 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.194 |  0.173 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.021 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.132 |  0.205 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.012 |  0.012 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.179 |  0.178 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 |  0.001 | -0.054 |  0.073 |  0.035 | torch.Size([30]) || layers.1.conv.bias
 |  0.990 |  0.872 |  1.330 |  0.079 | torch.Size([30]) || norm.weight
 | -0.000 | -0.120 |  0.097 |  0.039 | torch.Size([30]) || norm.bias
 |  0.000 | -0.215 |  0.229 |  0.039 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 |  0.005 | -0.045 |  0.051 |  0.031 | torch.Size([30]) || conv_after_body.bias
 | -0.001 | -0.156 |  0.230 |  0.036 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.004 | -0.039 |  0.034 |  0.024 | torch.Size([12]) || upsample.0.bias

22-11-08 13:35:02.499 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution\swinir_sr_lightweight_x2\models\25000_G.pth
    pretrained_netE: superresolution\swinir_sr_lightweight_x2\models\25000_E.pth
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: superresolution\swinir_sr_lightweight_x2\models\25000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 4
      dataloader_batch_size: 32
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-08 13:35:02.537 : Number of train images: 3,550, iters: 111
22-11-08 13:35:04.024 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-08 13:35:04.077 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.003 | -0.240 |  0.245 |  0.110 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.038 | -0.187 |  0.226 |  0.120 | torch.Size([30]) || conv_first.bias
 |  1.001 |  0.948 |  1.096 |  0.029 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 | -0.024 |  0.036 |  0.015 | torch.Size([30]) || patch_embed.norm.bias
 |  1.061 |  1.012 |  1.196 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 | -0.001 | -0.022 |  0.028 |  0.012 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 | -0.077 | -1.031 |  1.767 |  0.279 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.001 | -0.631 |  0.742 |  0.133 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.007 | -0.167 |  0.243 |  0.055 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.213 |  0.097 |  0.030 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.030 |  0.034 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.065 |  1.014 |  1.157 |  0.042 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 | -0.004 | -0.026 |  0.029 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.282 |  0.174 |  0.045 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.012 | -0.025 |  0.045 |  0.015 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.209 |  0.203 |  0.038 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 | -0.000 | -0.028 |  0.034 |  0.016 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.087 |  1.000 |  1.251 |  0.054 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.030 |  0.042 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.122 | -1.551 |  2.576 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 | -0.001 | -0.744 |  0.759 |  0.171 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 | -0.006 | -0.294 |  0.266 |  0.082 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.001 | -0.265 |  0.193 |  0.035 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 | -0.020 |  0.031 |  0.010 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.060 |  0.988 |  1.187 |  0.045 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 | -0.022 |  0.030 |  0.015 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.236 |  0.235 |  0.044 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.005 | -0.020 |  0.038 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.228 |  0.173 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 | -0.019 |  0.033 |  0.011 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.160 |  1.045 |  1.328 |  0.076 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.042 |  0.056 |  0.022 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.206 | -1.663 |  2.224 |  0.396 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.781 |  0.872 |  0.187 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 | -0.004 | -0.172 |  0.148 |  0.050 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.002 | -0.218 |  0.353 |  0.047 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.014 |  0.025 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.062 |  1.009 |  1.144 |  0.038 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.001 | -0.033 |  0.045 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.288 |  0.185 |  0.043 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.005 | -0.028 |  0.045 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.286 |  0.217 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 | -0.017 |  0.025 |  0.009 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.141 |  1.008 |  1.416 |  0.081 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.002 | -0.032 |  0.057 |  0.019 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.150 | -1.948 |  2.200 |  0.350 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -1.201 |  0.883 |  0.174 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 | -0.006 | -0.175 |  0.113 |  0.044 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.336 |  0.373 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 | -0.000 | -0.009 |  0.022 |  0.006 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.047 |  0.998 |  1.132 |  0.037 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 | -0.004 | -0.036 |  0.040 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.001 | -0.190 |  0.241 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 | -0.001 | -0.034 |  0.021 |  0.012 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.172 |  0.181 |  0.033 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.024 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.168 |  1.029 |  1.347 |  0.082 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 | -0.002 | -0.063 |  0.079 |  0.028 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.160 | -1.015 |  1.922 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.003 | -0.863 |  0.708 |  0.166 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 | -0.003 | -0.127 |  0.087 |  0.035 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.409 |  0.364 |  0.055 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.010 |  0.018 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.048 |  0.985 |  1.145 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.001 | -0.036 |  0.044 |  0.021 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.218 |  0.168 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.004 | -0.022 |  0.019 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.146 |  0.172 |  0.032 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.015 |  0.023 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.108 |  0.936 |  1.483 |  0.097 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 | -0.003 | -0.045 |  0.073 |  0.029 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.093 | -1.084 |  2.083 |  0.254 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 |  0.001 | -1.182 |  0.948 |  0.172 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 | -0.006 | -0.154 |  0.095 |  0.038 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.002 | -0.276 |  0.330 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.001 | -0.010 |  0.017 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.045 |  0.968 |  1.158 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 | -0.003 | -0.063 |  0.050 |  0.025 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.155 |  0.218 |  0.036 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.020 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.001 | -0.129 |  0.146 |  0.029 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.013 |  0.021 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.155 |  0.242 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.009 | -0.085 |  0.064 |  0.038 | torch.Size([30]) || layers.0.conv.bias
 |  1.025 |  0.964 |  1.204 |  0.047 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.002 | -0.032 |  0.046 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.019 | -0.788 |  1.875 |  0.158 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.001 | -0.665 |  0.603 |  0.127 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.002 | -0.152 |  0.156 |  0.052 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.113 |  0.161 |  0.028 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.012 |  0.015 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.036 |  0.983 |  1.294 |  0.060 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.003 | -0.036 |  0.038 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.186 |  0.273 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.001 | -0.027 |  0.026 |  0.013 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.001 | -0.203 |  0.161 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.001 | -0.016 |  0.013 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.041 |  0.972 |  1.253 |  0.059 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.036 |  0.042 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.023 | -0.661 |  2.265 |  0.175 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.750 |  0.763 |  0.169 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 | -0.008 | -0.293 |  0.270 |  0.077 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.121 |  0.120 |  0.029 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.001 | -0.011 |  0.018 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.047 |  0.979 |  1.276 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.001 | -0.045 |  0.055 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.232 |  0.193 |  0.037 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.001 | -0.029 |  0.025 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.163 |  0.198 |  0.033 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.001 | -0.014 |  0.016 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.070 |  1.001 |  1.302 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.040 |  0.021 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.043 | -0.950 |  2.164 |  0.207 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.822 |  0.914 |  0.150 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.005 | -0.177 |  0.202 |  0.063 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.183 |  0.158 |  0.030 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.010 |  0.015 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.039 |  0.957 |  1.251 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.003 | -0.033 |  0.059 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.275 |  0.134 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.001 | -0.023 |  0.029 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.001 | -0.183 |  0.133 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 | -0.000 | -0.014 |  0.010 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.045 |  0.992 |  1.201 |  0.057 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 | -0.001 | -0.035 |  0.024 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.027 | -1.357 |  1.919 |  0.218 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.819 |  1.021 |  0.167 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.004 | -0.197 |  0.209 |  0.079 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.131 |  0.139 |  0.031 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 | -0.015 |  0.011 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.051 |  0.980 |  1.268 |  0.073 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 | -0.002 | -0.042 |  0.034 |  0.022 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.204 |  0.392 |  0.039 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.002 | -0.016 |  0.027 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.115 |  0.175 |  0.032 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.013 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.068 |  0.850 |  1.515 |  0.122 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 | -0.003 | -0.034 |  0.022 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.064 | -1.056 |  1.562 |  0.240 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.734 |  0.800 |  0.160 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 | -0.005 | -0.213 |  0.218 |  0.061 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.208 |  0.163 |  0.034 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.011 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.042 |  0.969 |  1.276 |  0.064 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.002 | -0.044 |  0.037 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.173 |  0.335 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.003 | -0.021 |  0.026 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.112 |  0.160 |  0.029 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.014 |  0.012 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.103 |  0.981 |  1.370 |  0.107 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.002 | -0.036 |  0.039 |  0.020 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.065 | -1.210 |  2.978 |  0.243 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 |  0.002 | -0.905 |  0.866 |  0.182 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.001 | -0.248 |  0.198 |  0.067 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.002 | -0.217 |  0.194 |  0.039 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 | -0.010 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.043 |  0.979 |  1.275 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.004 | -0.037 |  0.047 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.194 |  0.173 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.021 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.132 |  0.205 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.012 |  0.012 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.179 |  0.178 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 |  0.001 | -0.054 |  0.073 |  0.035 | torch.Size([30]) || layers.1.conv.bias
 |  0.990 |  0.872 |  1.330 |  0.079 | torch.Size([30]) || norm.weight
 | -0.000 | -0.120 |  0.097 |  0.039 | torch.Size([30]) || norm.bias
 |  0.000 | -0.215 |  0.229 |  0.039 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 |  0.005 | -0.045 |  0.051 |  0.031 | torch.Size([30]) || conv_after_body.bias
 | -0.001 | -0.156 |  0.230 |  0.036 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.004 | -0.039 |  0.034 |  0.024 | torch.Size([12]) || upsample.0.bias

22-11-08 13:38:03.469 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution\swinir_sr_lightweight_x2\models\25000_G.pth
    pretrained_netE: superresolution\swinir_sr_lightweight_x2\models\25000_E.pth
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: superresolution\swinir_sr_lightweight_x2\models\25000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 2
      dataloader_batch_size: 16
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-08 13:38:03.503 : Number of train images: 3,550, iters: 222
22-11-08 13:38:04.901 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-08 13:38:04.964 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.003 | -0.240 |  0.245 |  0.110 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.038 | -0.187 |  0.226 |  0.120 | torch.Size([30]) || conv_first.bias
 |  1.001 |  0.948 |  1.096 |  0.029 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 | -0.024 |  0.036 |  0.015 | torch.Size([30]) || patch_embed.norm.bias
 |  1.061 |  1.012 |  1.196 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 | -0.001 | -0.022 |  0.028 |  0.012 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 | -0.077 | -1.031 |  1.767 |  0.279 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.001 | -0.631 |  0.742 |  0.133 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.007 | -0.167 |  0.243 |  0.055 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.213 |  0.097 |  0.030 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.030 |  0.034 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.065 |  1.014 |  1.157 |  0.042 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 | -0.004 | -0.026 |  0.029 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.282 |  0.174 |  0.045 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.012 | -0.025 |  0.045 |  0.015 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.209 |  0.203 |  0.038 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 | -0.000 | -0.028 |  0.034 |  0.016 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.087 |  1.000 |  1.251 |  0.054 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.030 |  0.042 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.122 | -1.551 |  2.576 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 | -0.001 | -0.744 |  0.759 |  0.171 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 | -0.006 | -0.294 |  0.266 |  0.082 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.001 | -0.265 |  0.193 |  0.035 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 | -0.020 |  0.031 |  0.010 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.060 |  0.988 |  1.187 |  0.045 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 | -0.022 |  0.030 |  0.015 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.236 |  0.235 |  0.044 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.005 | -0.020 |  0.038 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.228 |  0.173 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 | -0.019 |  0.033 |  0.011 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.160 |  1.045 |  1.328 |  0.076 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.042 |  0.056 |  0.022 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.206 | -1.663 |  2.224 |  0.396 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.781 |  0.872 |  0.187 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 | -0.004 | -0.172 |  0.148 |  0.050 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.002 | -0.218 |  0.353 |  0.047 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.014 |  0.025 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.062 |  1.009 |  1.144 |  0.038 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.001 | -0.033 |  0.045 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.288 |  0.185 |  0.043 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.005 | -0.028 |  0.045 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.286 |  0.217 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 | -0.017 |  0.025 |  0.009 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.141 |  1.008 |  1.416 |  0.081 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.002 | -0.032 |  0.057 |  0.019 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.150 | -1.948 |  2.200 |  0.350 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -1.201 |  0.883 |  0.174 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 | -0.006 | -0.175 |  0.113 |  0.044 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.336 |  0.373 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 | -0.000 | -0.009 |  0.022 |  0.006 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.047 |  0.998 |  1.132 |  0.037 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 | -0.004 | -0.036 |  0.040 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.001 | -0.190 |  0.241 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 | -0.001 | -0.034 |  0.021 |  0.012 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.172 |  0.181 |  0.033 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.024 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.168 |  1.029 |  1.347 |  0.082 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 | -0.002 | -0.063 |  0.079 |  0.028 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.160 | -1.015 |  1.922 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.003 | -0.863 |  0.708 |  0.166 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 | -0.003 | -0.127 |  0.087 |  0.035 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.409 |  0.364 |  0.055 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.010 |  0.018 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.048 |  0.985 |  1.145 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.001 | -0.036 |  0.044 |  0.021 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.218 |  0.168 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.004 | -0.022 |  0.019 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.146 |  0.172 |  0.032 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.015 |  0.023 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.108 |  0.936 |  1.483 |  0.097 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 | -0.003 | -0.045 |  0.073 |  0.029 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.093 | -1.084 |  2.083 |  0.254 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 |  0.001 | -1.182 |  0.948 |  0.172 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 | -0.006 | -0.154 |  0.095 |  0.038 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.002 | -0.276 |  0.330 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.001 | -0.010 |  0.017 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.045 |  0.968 |  1.158 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 | -0.003 | -0.063 |  0.050 |  0.025 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.155 |  0.218 |  0.036 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.020 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.001 | -0.129 |  0.146 |  0.029 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.013 |  0.021 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.155 |  0.242 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.009 | -0.085 |  0.064 |  0.038 | torch.Size([30]) || layers.0.conv.bias
 |  1.025 |  0.964 |  1.204 |  0.047 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.002 | -0.032 |  0.046 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.019 | -0.788 |  1.875 |  0.158 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.001 | -0.665 |  0.603 |  0.127 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.002 | -0.152 |  0.156 |  0.052 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.113 |  0.161 |  0.028 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.012 |  0.015 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.036 |  0.983 |  1.294 |  0.060 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.003 | -0.036 |  0.038 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.186 |  0.273 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.001 | -0.027 |  0.026 |  0.013 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.001 | -0.203 |  0.161 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.001 | -0.016 |  0.013 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.041 |  0.972 |  1.253 |  0.059 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.036 |  0.042 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.023 | -0.661 |  2.265 |  0.175 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.750 |  0.763 |  0.169 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 | -0.008 | -0.293 |  0.270 |  0.077 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.121 |  0.120 |  0.029 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.001 | -0.011 |  0.018 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.047 |  0.979 |  1.276 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.001 | -0.045 |  0.055 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.232 |  0.193 |  0.037 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.001 | -0.029 |  0.025 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.163 |  0.198 |  0.033 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.001 | -0.014 |  0.016 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.070 |  1.001 |  1.302 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.040 |  0.021 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.043 | -0.950 |  2.164 |  0.207 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.822 |  0.914 |  0.150 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.005 | -0.177 |  0.202 |  0.063 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.183 |  0.158 |  0.030 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.010 |  0.015 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.039 |  0.957 |  1.251 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.003 | -0.033 |  0.059 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.275 |  0.134 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.001 | -0.023 |  0.029 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.001 | -0.183 |  0.133 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 | -0.000 | -0.014 |  0.010 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.045 |  0.992 |  1.201 |  0.057 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 | -0.001 | -0.035 |  0.024 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.027 | -1.357 |  1.919 |  0.218 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.819 |  1.021 |  0.167 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.004 | -0.197 |  0.209 |  0.079 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.131 |  0.139 |  0.031 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 | -0.015 |  0.011 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.051 |  0.980 |  1.268 |  0.073 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 | -0.002 | -0.042 |  0.034 |  0.022 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.204 |  0.392 |  0.039 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.002 | -0.016 |  0.027 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.115 |  0.175 |  0.032 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.013 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.068 |  0.850 |  1.515 |  0.122 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 | -0.003 | -0.034 |  0.022 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.064 | -1.056 |  1.562 |  0.240 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.734 |  0.800 |  0.160 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 | -0.005 | -0.213 |  0.218 |  0.061 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.208 |  0.163 |  0.034 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.011 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.042 |  0.969 |  1.276 |  0.064 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.002 | -0.044 |  0.037 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.173 |  0.335 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.003 | -0.021 |  0.026 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.112 |  0.160 |  0.029 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.014 |  0.012 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.103 |  0.981 |  1.370 |  0.107 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.002 | -0.036 |  0.039 |  0.020 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.065 | -1.210 |  2.978 |  0.243 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 |  0.002 | -0.905 |  0.866 |  0.182 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.001 | -0.248 |  0.198 |  0.067 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.002 | -0.217 |  0.194 |  0.039 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 | -0.010 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.043 |  0.979 |  1.275 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.004 | -0.037 |  0.047 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.194 |  0.173 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.021 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.132 |  0.205 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.012 |  0.012 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.179 |  0.178 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 |  0.001 | -0.054 |  0.073 |  0.035 | torch.Size([30]) || layers.1.conv.bias
 |  0.990 |  0.872 |  1.330 |  0.079 | torch.Size([30]) || norm.weight
 | -0.000 | -0.120 |  0.097 |  0.039 | torch.Size([30]) || norm.bias
 |  0.000 | -0.215 |  0.229 |  0.039 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 |  0.005 | -0.045 |  0.051 |  0.031 | torch.Size([30]) || conv_after_body.bias
 | -0.001 | -0.156 |  0.230 |  0.036 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.004 | -0.039 |  0.034 |  0.024 | torch.Size([12]) || upsample.0.bias

22-11-08 13:39:36.464 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution\swinir_sr_lightweight_x2\models\25000_G.pth
    pretrained_netE: superresolution\swinir_sr_lightweight_x2\models\25000_E.pth
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: superresolution\swinir_sr_lightweight_x2\models\25000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 2
      dataloader_batch_size: 8
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-08 13:39:36.500 : Number of train images: 3,550, iters: 444
22-11-08 13:39:38.043 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-08 13:39:38.096 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.003 | -0.240 |  0.245 |  0.110 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.038 | -0.187 |  0.226 |  0.120 | torch.Size([30]) || conv_first.bias
 |  1.001 |  0.948 |  1.096 |  0.029 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 | -0.024 |  0.036 |  0.015 | torch.Size([30]) || patch_embed.norm.bias
 |  1.061 |  1.012 |  1.196 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 | -0.001 | -0.022 |  0.028 |  0.012 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 | -0.077 | -1.031 |  1.767 |  0.279 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.001 | -0.631 |  0.742 |  0.133 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.007 | -0.167 |  0.243 |  0.055 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.213 |  0.097 |  0.030 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.030 |  0.034 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.065 |  1.014 |  1.157 |  0.042 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 | -0.004 | -0.026 |  0.029 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.282 |  0.174 |  0.045 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.012 | -0.025 |  0.045 |  0.015 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.209 |  0.203 |  0.038 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 | -0.000 | -0.028 |  0.034 |  0.016 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.087 |  1.000 |  1.251 |  0.054 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.030 |  0.042 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.122 | -1.551 |  2.576 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 | -0.001 | -0.744 |  0.759 |  0.171 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 | -0.006 | -0.294 |  0.266 |  0.082 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.001 | -0.265 |  0.193 |  0.035 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 | -0.020 |  0.031 |  0.010 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.060 |  0.988 |  1.187 |  0.045 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 | -0.022 |  0.030 |  0.015 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.236 |  0.235 |  0.044 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.005 | -0.020 |  0.038 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.228 |  0.173 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 | -0.019 |  0.033 |  0.011 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.160 |  1.045 |  1.328 |  0.076 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.042 |  0.056 |  0.022 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.206 | -1.663 |  2.224 |  0.396 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.781 |  0.872 |  0.187 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 | -0.004 | -0.172 |  0.148 |  0.050 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.002 | -0.218 |  0.353 |  0.047 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.014 |  0.025 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.062 |  1.009 |  1.144 |  0.038 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.001 | -0.033 |  0.045 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.288 |  0.185 |  0.043 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.005 | -0.028 |  0.045 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.286 |  0.217 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 | -0.017 |  0.025 |  0.009 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.141 |  1.008 |  1.416 |  0.081 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.002 | -0.032 |  0.057 |  0.019 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.150 | -1.948 |  2.200 |  0.350 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -1.201 |  0.883 |  0.174 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 | -0.006 | -0.175 |  0.113 |  0.044 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.336 |  0.373 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 | -0.000 | -0.009 |  0.022 |  0.006 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.047 |  0.998 |  1.132 |  0.037 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 | -0.004 | -0.036 |  0.040 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.001 | -0.190 |  0.241 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 | -0.001 | -0.034 |  0.021 |  0.012 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.172 |  0.181 |  0.033 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.024 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.168 |  1.029 |  1.347 |  0.082 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 | -0.002 | -0.063 |  0.079 |  0.028 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.160 | -1.015 |  1.922 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.003 | -0.863 |  0.708 |  0.166 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 | -0.003 | -0.127 |  0.087 |  0.035 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.409 |  0.364 |  0.055 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.010 |  0.018 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.048 |  0.985 |  1.145 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.001 | -0.036 |  0.044 |  0.021 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.218 |  0.168 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.004 | -0.022 |  0.019 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.146 |  0.172 |  0.032 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.015 |  0.023 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.108 |  0.936 |  1.483 |  0.097 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 | -0.003 | -0.045 |  0.073 |  0.029 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.093 | -1.084 |  2.083 |  0.254 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 |  0.001 | -1.182 |  0.948 |  0.172 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 | -0.006 | -0.154 |  0.095 |  0.038 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.002 | -0.276 |  0.330 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.001 | -0.010 |  0.017 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.045 |  0.968 |  1.158 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 | -0.003 | -0.063 |  0.050 |  0.025 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.155 |  0.218 |  0.036 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.020 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.001 | -0.129 |  0.146 |  0.029 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.013 |  0.021 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.155 |  0.242 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.009 | -0.085 |  0.064 |  0.038 | torch.Size([30]) || layers.0.conv.bias
 |  1.025 |  0.964 |  1.204 |  0.047 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.002 | -0.032 |  0.046 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.019 | -0.788 |  1.875 |  0.158 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.001 | -0.665 |  0.603 |  0.127 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.002 | -0.152 |  0.156 |  0.052 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.113 |  0.161 |  0.028 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.012 |  0.015 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.036 |  0.983 |  1.294 |  0.060 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.003 | -0.036 |  0.038 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.186 |  0.273 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.001 | -0.027 |  0.026 |  0.013 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.001 | -0.203 |  0.161 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.001 | -0.016 |  0.013 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.041 |  0.972 |  1.253 |  0.059 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.036 |  0.042 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.023 | -0.661 |  2.265 |  0.175 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.750 |  0.763 |  0.169 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 | -0.008 | -0.293 |  0.270 |  0.077 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.121 |  0.120 |  0.029 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.001 | -0.011 |  0.018 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.047 |  0.979 |  1.276 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.001 | -0.045 |  0.055 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.232 |  0.193 |  0.037 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.001 | -0.029 |  0.025 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.163 |  0.198 |  0.033 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.001 | -0.014 |  0.016 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.070 |  1.001 |  1.302 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.040 |  0.021 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.043 | -0.950 |  2.164 |  0.207 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.822 |  0.914 |  0.150 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.005 | -0.177 |  0.202 |  0.063 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.183 |  0.158 |  0.030 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.010 |  0.015 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.039 |  0.957 |  1.251 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.003 | -0.033 |  0.059 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.275 |  0.134 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.001 | -0.023 |  0.029 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.001 | -0.183 |  0.133 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 | -0.000 | -0.014 |  0.010 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.045 |  0.992 |  1.201 |  0.057 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 | -0.001 | -0.035 |  0.024 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.027 | -1.357 |  1.919 |  0.218 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.819 |  1.021 |  0.167 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.004 | -0.197 |  0.209 |  0.079 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.131 |  0.139 |  0.031 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 | -0.015 |  0.011 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.051 |  0.980 |  1.268 |  0.073 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 | -0.002 | -0.042 |  0.034 |  0.022 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.204 |  0.392 |  0.039 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.002 | -0.016 |  0.027 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.115 |  0.175 |  0.032 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.013 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.068 |  0.850 |  1.515 |  0.122 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 | -0.003 | -0.034 |  0.022 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.064 | -1.056 |  1.562 |  0.240 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.734 |  0.800 |  0.160 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 | -0.005 | -0.213 |  0.218 |  0.061 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.208 |  0.163 |  0.034 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.011 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.042 |  0.969 |  1.276 |  0.064 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.002 | -0.044 |  0.037 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.173 |  0.335 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.003 | -0.021 |  0.026 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.112 |  0.160 |  0.029 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.014 |  0.012 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.103 |  0.981 |  1.370 |  0.107 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.002 | -0.036 |  0.039 |  0.020 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.065 | -1.210 |  2.978 |  0.243 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 |  0.002 | -0.905 |  0.866 |  0.182 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.001 | -0.248 |  0.198 |  0.067 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.002 | -0.217 |  0.194 |  0.039 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 | -0.010 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.043 |  0.979 |  1.275 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.004 | -0.037 |  0.047 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.194 |  0.173 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.021 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.132 |  0.205 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.012 |  0.012 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.179 |  0.178 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 |  0.001 | -0.054 |  0.073 |  0.035 | torch.Size([30]) || layers.1.conv.bias
 |  0.990 |  0.872 |  1.330 |  0.079 | torch.Size([30]) || norm.weight
 | -0.000 | -0.120 |  0.097 |  0.039 | torch.Size([30]) || norm.bias
 |  0.000 | -0.215 |  0.229 |  0.039 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 |  0.005 | -0.045 |  0.051 |  0.031 | torch.Size([30]) || conv_after_body.bias
 | -0.001 | -0.156 |  0.230 |  0.036 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.004 | -0.039 |  0.034 |  0.024 | torch.Size([12]) || upsample.0.bias

22-11-08 17:32:17.258 :   task: swinir_sr_lightweight_x2
  model: plain
  gpu_ids: [0, 1, 2, 3, 4, 5, 6, 7]
  dist: False
  scale: 2
  n_channels: 3
  path:[
    root: superresolution
    pretrained_netG: superresolution\swinir_sr_lightweight_x2\models\25000_G.pth
    pretrained_netE: superresolution\swinir_sr_lightweight_x2\models\25000_E.pth
    task: superresolution\swinir_sr_lightweight_x2
    log: superresolution\swinir_sr_lightweight_x2
    options: superresolution\swinir_sr_lightweight_x2\options
    models: superresolution\swinir_sr_lightweight_x2\models
    images: superresolution\swinir_sr_lightweight_x2\images
    pretrained_optimizerG: superresolution\swinir_sr_lightweight_x2\models\25000_optimizerG.pth
  ]
  datasets:[
    train:[
      name: train_dataset
      dataset_type: sr
      dataroot_H: trainsets/trainH
      dataroot_L: trainsets/trainL
      H_size: 128
      dataloader_shuffle: True
      dataloader_num_workers: 4
      dataloader_batch_size: 32
      phase: train
      scale: 2
      n_channels: 3
    ]
    test:[
      name: test_dataset
      dataset_type: sr
      dataroot_H: testsets/Set5/HR
      dataroot_L: testsets/Set5/LR_bicubic/X2
      phase: test
      scale: 2
      n_channels: 3
    ]
  ]
  netG:[
    net_type: swinir
    upscale: 2
    in_chans: 3
    img_size: 64
    window_size: 8
    img_range: 1.0
    depths: [6, 6]
    embed_dim: 30
    num_heads: [6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffledirect
    resi_connection: 1conv
    init_type: default
    scale: 2
  ]
  train:[
    G_lossfn_type: l1
    G_lossfn_weight: 1.0
    E_decay: 0.999
    G_optimizer_type: adam
    G_optimizer_lr: 0.0002
    G_optimizer_wd: 0
    G_optimizer_clipgrad: None
    G_optimizer_reuse: True
    G_scheduler_type: MultiStepLR
    G_scheduler_milestones: [250000, 400000, 450000, 475000, 500000]
    G_scheduler_gamma: 0.5
    G_regularizer_orthstep: None
    G_regularizer_clipstep: None
    G_param_strict: True
    E_param_strict: True
    checkpoint_test: 5000
    checkpoint_save: 5000
    checkpoint_print: 200
    F_feature_layer: 34
    F_weights: 1.0
    F_lossfn_type: l1
    F_use_input_norm: True
    F_use_range_norm: False
    G_optimizer_betas: [0.9, 0.999]
    G_scheduler_restart_weights: 1
  ]
  opt_path: options/swinir/train_swinir_sr_lightweight.json
  is_train: True
  merge_bn: False
  merge_bn_startpoint: -1
  find_unused_parameters: True
  use_static_graph: False
  num_gpu: 8
  rank: 0
  world_size: 1

22-11-08 17:32:17.292 : Number of train images: 3,550, iters: 111
22-11-08 17:32:18.908 : 
Networks name: SwinIR
Params number: 135162
Net structure:
SwinIR(
  (conv_first): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RSTB(
      (residual_group): BasicLayer(
        dim=30, input_resolution=(64, 64), depth=6
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=0, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim=30, input_resolution=(64, 64), num_heads=6, window_size=8, shift_size=4, mlp_ratio=2
            (norm1): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=30, window_size=(8, 8), num_heads=6
              (qkv): Linear(in_features=30, out_features=90, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=30, out_features=30, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=30, out_features=60, bias=True)
              (act): GELU(approximate=none)
              (fc2): Linear(in_features=60, out_features=30, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (conv): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(30, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsample): UpsampleOneStep(
    (0): Conv2d(30, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
  )
)

22-11-08 17:32:18.961 : 
 |  mean  |  min   |  max   |  std   || shape               
 | -0.003 | -0.240 |  0.245 |  0.110 | torch.Size([30, 3, 3, 3]) || conv_first.weight
 |  0.038 | -0.187 |  0.226 |  0.120 | torch.Size([30]) || conv_first.bias
 |  1.001 |  0.948 |  1.096 |  0.029 | torch.Size([30]) || patch_embed.norm.weight
 |  0.000 | -0.024 |  0.036 |  0.015 | torch.Size([30]) || patch_embed.norm.bias
 |  1.061 |  1.012 |  1.196 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.weight
 | -0.001 | -0.022 |  0.028 |  0.012 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm1.bias
 | -0.077 | -1.031 |  1.767 |  0.279 | torch.Size([225, 6]) || layers.0.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.0.attn.relative_position_index
 |  0.001 | -0.631 |  0.742 |  0.133 | torch.Size([90, 30]) || layers.0.residual_group.blocks.0.attn.qkv.weight
 |  0.007 | -0.167 |  0.243 |  0.055 | torch.Size([90]) || layers.0.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.213 |  0.097 |  0.030 | torch.Size([30, 30]) || layers.0.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.030 |  0.034 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.attn.proj.bias
 |  1.065 |  1.014 |  1.157 |  0.042 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.weight
 | -0.004 | -0.026 |  0.029 |  0.017 | torch.Size([30]) || layers.0.residual_group.blocks.0.norm2.bias
 |  0.000 | -0.282 |  0.174 |  0.045 | torch.Size([60, 30]) || layers.0.residual_group.blocks.0.mlp.fc1.weight
 |  0.012 | -0.025 |  0.045 |  0.015 | torch.Size([60]) || layers.0.residual_group.blocks.0.mlp.fc1.bias
 |  0.000 | -0.209 |  0.203 |  0.038 | torch.Size([30, 60]) || layers.0.residual_group.blocks.0.mlp.fc2.weight
 | -0.000 | -0.028 |  0.034 |  0.016 | torch.Size([30]) || layers.0.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.1.attn_mask
 |  1.087 |  1.000 |  1.251 |  0.054 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.030 |  0.042 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm1.bias
 | -0.122 | -1.551 |  2.576 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.1.attn.relative_position_index
 | -0.001 | -0.744 |  0.759 |  0.171 | torch.Size([90, 30]) || layers.0.residual_group.blocks.1.attn.qkv.weight
 | -0.006 | -0.294 |  0.266 |  0.082 | torch.Size([90]) || layers.0.residual_group.blocks.1.attn.qkv.bias
 | -0.001 | -0.265 |  0.193 |  0.035 | torch.Size([30, 30]) || layers.0.residual_group.blocks.1.attn.proj.weight
 |  0.000 | -0.020 |  0.031 |  0.010 | torch.Size([30]) || layers.0.residual_group.blocks.1.attn.proj.bias
 |  1.060 |  0.988 |  1.187 |  0.045 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.weight
 |  0.000 | -0.022 |  0.030 |  0.015 | torch.Size([30]) || layers.0.residual_group.blocks.1.norm2.bias
 |  0.001 | -0.236 |  0.235 |  0.044 | torch.Size([60, 30]) || layers.0.residual_group.blocks.1.mlp.fc1.weight
 |  0.005 | -0.020 |  0.038 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.228 |  0.173 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.1.mlp.fc2.weight
 |  0.000 | -0.019 |  0.033 |  0.011 | torch.Size([30]) || layers.0.residual_group.blocks.1.mlp.fc2.bias
 |  1.160 |  1.045 |  1.328 |  0.076 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.042 |  0.056 |  0.022 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm1.bias
 | -0.206 | -1.663 |  2.224 |  0.396 | torch.Size([225, 6]) || layers.0.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.781 |  0.872 |  0.187 | torch.Size([90, 30]) || layers.0.residual_group.blocks.2.attn.qkv.weight
 | -0.004 | -0.172 |  0.148 |  0.050 | torch.Size([90]) || layers.0.residual_group.blocks.2.attn.qkv.bias
 |  0.002 | -0.218 |  0.353 |  0.047 | torch.Size([30, 30]) || layers.0.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.014 |  0.025 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.2.attn.proj.bias
 |  1.062 |  1.009 |  1.144 |  0.038 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.weight
 |  0.001 | -0.033 |  0.045 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.2.norm2.bias
 | -0.001 | -0.288 |  0.185 |  0.043 | torch.Size([60, 30]) || layers.0.residual_group.blocks.2.mlp.fc1.weight
 |  0.005 | -0.028 |  0.045 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.2.mlp.fc1.bias
 | -0.000 | -0.286 |  0.217 |  0.036 | torch.Size([30, 60]) || layers.0.residual_group.blocks.2.mlp.fc2.weight
 |  0.000 | -0.017 |  0.025 |  0.009 | torch.Size([30]) || layers.0.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.3.attn_mask
 |  1.141 |  1.008 |  1.416 |  0.081 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.weight
 |  0.002 | -0.032 |  0.057 |  0.019 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm1.bias
 | -0.150 | -1.948 |  2.200 |  0.350 | torch.Size([225, 6]) || layers.0.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.3.attn.relative_position_index
 |  0.001 | -1.201 |  0.883 |  0.174 | torch.Size([90, 30]) || layers.0.residual_group.blocks.3.attn.qkv.weight
 | -0.006 | -0.175 |  0.113 |  0.044 | torch.Size([90]) || layers.0.residual_group.blocks.3.attn.qkv.bias
 | -0.000 | -0.336 |  0.373 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.3.attn.proj.weight
 | -0.000 | -0.009 |  0.022 |  0.006 | torch.Size([30]) || layers.0.residual_group.blocks.3.attn.proj.bias
 |  1.047 |  0.998 |  1.132 |  0.037 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.weight
 | -0.004 | -0.036 |  0.040 |  0.020 | torch.Size([30]) || layers.0.residual_group.blocks.3.norm2.bias
 |  0.001 | -0.190 |  0.241 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.3.mlp.fc1.weight
 | -0.001 | -0.034 |  0.021 |  0.012 | torch.Size([60]) || layers.0.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.172 |  0.181 |  0.033 | torch.Size([30, 60]) || layers.0.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.024 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.3.mlp.fc2.bias
 |  1.168 |  1.029 |  1.347 |  0.082 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.weight
 | -0.002 | -0.063 |  0.079 |  0.028 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm1.bias
 | -0.160 | -1.015 |  1.922 |  0.318 | torch.Size([225, 6]) || layers.0.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.4.attn.relative_position_index
 |  0.003 | -0.863 |  0.708 |  0.166 | torch.Size([90, 30]) || layers.0.residual_group.blocks.4.attn.qkv.weight
 | -0.003 | -0.127 |  0.087 |  0.035 | torch.Size([90]) || layers.0.residual_group.blocks.4.attn.qkv.bias
 | -0.001 | -0.409 |  0.364 |  0.055 | torch.Size([30, 30]) || layers.0.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.010 |  0.018 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.4.attn.proj.bias
 |  1.048 |  0.985 |  1.145 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.weight
 |  0.001 | -0.036 |  0.044 |  0.021 | torch.Size([30]) || layers.0.residual_group.blocks.4.norm2.bias
 |  0.000 | -0.218 |  0.168 |  0.037 | torch.Size([60, 30]) || layers.0.residual_group.blocks.4.mlp.fc1.weight
 |  0.004 | -0.022 |  0.019 |  0.011 | torch.Size([60]) || layers.0.residual_group.blocks.4.mlp.fc1.bias
 |  0.001 | -0.146 |  0.172 |  0.032 | torch.Size([30, 60]) || layers.0.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.015 |  0.023 |  0.008 | torch.Size([30]) || layers.0.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.0.residual_group.blocks.5.attn_mask
 |  1.108 |  0.936 |  1.483 |  0.097 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.weight
 | -0.003 | -0.045 |  0.073 |  0.029 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm1.bias
 | -0.093 | -1.084 |  2.083 |  0.254 | torch.Size([225, 6]) || layers.0.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.0.residual_group.blocks.5.attn.relative_position_index
 |  0.001 | -1.182 |  0.948 |  0.172 | torch.Size([90, 30]) || layers.0.residual_group.blocks.5.attn.qkv.weight
 | -0.006 | -0.154 |  0.095 |  0.038 | torch.Size([90]) || layers.0.residual_group.blocks.5.attn.qkv.bias
 | -0.002 | -0.276 |  0.330 |  0.045 | torch.Size([30, 30]) || layers.0.residual_group.blocks.5.attn.proj.weight
 |  0.001 | -0.010 |  0.017 |  0.005 | torch.Size([30]) || layers.0.residual_group.blocks.5.attn.proj.bias
 |  1.045 |  0.968 |  1.158 |  0.047 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.weight
 | -0.003 | -0.063 |  0.050 |  0.025 | torch.Size([30]) || layers.0.residual_group.blocks.5.norm2.bias
 |  0.001 | -0.155 |  0.218 |  0.036 | torch.Size([60, 30]) || layers.0.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.020 |  0.013 | torch.Size([60]) || layers.0.residual_group.blocks.5.mlp.fc1.bias
 |  0.001 | -0.129 |  0.146 |  0.029 | torch.Size([30, 60]) || layers.0.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.013 |  0.021 |  0.007 | torch.Size([30]) || layers.0.residual_group.blocks.5.mlp.fc2.bias
 |  0.000 | -0.155 |  0.242 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.0.conv.weight
 | -0.009 | -0.085 |  0.064 |  0.038 | torch.Size([30]) || layers.0.conv.bias
 |  1.025 |  0.964 |  1.204 |  0.047 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.weight
 |  0.002 | -0.032 |  0.046 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm1.bias
 | -0.019 | -0.788 |  1.875 |  0.158 | torch.Size([225, 6]) || layers.1.residual_group.blocks.0.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.0.attn.relative_position_index
 | -0.001 | -0.665 |  0.603 |  0.127 | torch.Size([90, 30]) || layers.1.residual_group.blocks.0.attn.qkv.weight
 |  0.002 | -0.152 |  0.156 |  0.052 | torch.Size([90]) || layers.1.residual_group.blocks.0.attn.qkv.bias
 |  0.000 | -0.113 |  0.161 |  0.028 | torch.Size([30, 30]) || layers.1.residual_group.blocks.0.attn.proj.weight
 |  0.000 | -0.012 |  0.015 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.0.attn.proj.bias
 |  1.036 |  0.983 |  1.294 |  0.060 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.weight
 |  0.003 | -0.036 |  0.038 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.0.norm2.bias
 |  0.001 | -0.186 |  0.273 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.0.mlp.fc1.weight
 |  0.001 | -0.027 |  0.026 |  0.013 | torch.Size([60]) || layers.1.residual_group.blocks.0.mlp.fc1.bias
 |  0.001 | -0.203 |  0.161 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.0.mlp.fc2.weight
 |  0.001 | -0.016 |  0.013 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.0.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.1.attn_mask
 |  1.041 |  0.972 |  1.253 |  0.059 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.weight
 | -0.002 | -0.036 |  0.042 |  0.017 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm1.bias
 | -0.023 | -0.661 |  2.265 |  0.175 | torch.Size([225, 6]) || layers.1.residual_group.blocks.1.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.1.attn.relative_position_index
 | -0.000 | -0.750 |  0.763 |  0.169 | torch.Size([90, 30]) || layers.1.residual_group.blocks.1.attn.qkv.weight
 | -0.008 | -0.293 |  0.270 |  0.077 | torch.Size([90]) || layers.1.residual_group.blocks.1.attn.qkv.bias
 | -0.000 | -0.121 |  0.120 |  0.029 | torch.Size([30, 30]) || layers.1.residual_group.blocks.1.attn.proj.weight
 |  0.001 | -0.011 |  0.018 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.1.attn.proj.bias
 |  1.047 |  0.979 |  1.276 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.weight
 |  0.001 | -0.045 |  0.055 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.1.norm2.bias
 |  0.000 | -0.232 |  0.193 |  0.037 | torch.Size([60, 30]) || layers.1.residual_group.blocks.1.mlp.fc1.weight
 |  0.001 | -0.029 |  0.025 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.1.mlp.fc1.bias
 | -0.001 | -0.163 |  0.198 |  0.033 | torch.Size([30, 60]) || layers.1.residual_group.blocks.1.mlp.fc2.weight
 |  0.001 | -0.014 |  0.016 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.1.mlp.fc2.bias
 |  1.070 |  1.001 |  1.302 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.weight
 | -0.001 | -0.040 |  0.021 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm1.bias
 | -0.043 | -0.950 |  2.164 |  0.207 | torch.Size([225, 6]) || layers.1.residual_group.blocks.2.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.2.attn.relative_position_index
 |  0.000 | -0.822 |  0.914 |  0.150 | torch.Size([90, 30]) || layers.1.residual_group.blocks.2.attn.qkv.weight
 |  0.005 | -0.177 |  0.202 |  0.063 | torch.Size([90]) || layers.1.residual_group.blocks.2.attn.qkv.bias
 |  0.001 | -0.183 |  0.158 |  0.030 | torch.Size([30, 30]) || layers.1.residual_group.blocks.2.attn.proj.weight
 |  0.000 | -0.010 |  0.015 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.2.attn.proj.bias
 |  1.039 |  0.957 |  1.251 |  0.063 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.weight
 |  0.003 | -0.033 |  0.059 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.2.norm2.bias
 | -0.000 | -0.275 |  0.134 |  0.035 | torch.Size([60, 30]) || layers.1.residual_group.blocks.2.mlp.fc1.weight
 |  0.001 | -0.023 |  0.029 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.2.mlp.fc1.bias
 | -0.001 | -0.183 |  0.133 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.2.mlp.fc2.weight
 | -0.000 | -0.014 |  0.010 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.2.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.3.attn_mask
 |  1.045 |  0.992 |  1.201 |  0.057 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.weight
 | -0.001 | -0.035 |  0.024 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm1.bias
 | -0.027 | -1.357 |  1.919 |  0.218 | torch.Size([225, 6]) || layers.1.residual_group.blocks.3.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.3.attn.relative_position_index
 |  0.000 | -0.819 |  1.021 |  0.167 | torch.Size([90, 30]) || layers.1.residual_group.blocks.3.attn.qkv.weight
 |  0.004 | -0.197 |  0.209 |  0.079 | torch.Size([90]) || layers.1.residual_group.blocks.3.attn.qkv.bias
 | -0.001 | -0.131 |  0.139 |  0.031 | torch.Size([30, 30]) || layers.1.residual_group.blocks.3.attn.proj.weight
 |  0.000 | -0.015 |  0.011 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.3.attn.proj.bias
 |  1.051 |  0.980 |  1.268 |  0.073 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.weight
 | -0.002 | -0.042 |  0.034 |  0.022 | torch.Size([30]) || layers.1.residual_group.blocks.3.norm2.bias
 |  0.000 | -0.204 |  0.392 |  0.039 | torch.Size([60, 30]) || layers.1.residual_group.blocks.3.mlp.fc1.weight
 |  0.002 | -0.016 |  0.027 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.3.mlp.fc1.bias
 |  0.001 | -0.115 |  0.175 |  0.032 | torch.Size([30, 60]) || layers.1.residual_group.blocks.3.mlp.fc2.weight
 |  0.000 | -0.016 |  0.013 |  0.007 | torch.Size([30]) || layers.1.residual_group.blocks.3.mlp.fc2.bias
 |  1.068 |  0.850 |  1.515 |  0.122 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.weight
 | -0.003 | -0.034 |  0.022 |  0.014 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm1.bias
 | -0.064 | -1.056 |  1.562 |  0.240 | torch.Size([225, 6]) || layers.1.residual_group.blocks.4.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.4.attn.relative_position_index
 |  0.000 | -0.734 |  0.800 |  0.160 | torch.Size([90, 30]) || layers.1.residual_group.blocks.4.attn.qkv.weight
 | -0.005 | -0.213 |  0.218 |  0.061 | torch.Size([90]) || layers.1.residual_group.blocks.4.attn.qkv.bias
 | -0.000 | -0.208 |  0.163 |  0.034 | torch.Size([30, 30]) || layers.1.residual_group.blocks.4.attn.proj.weight
 |  0.000 | -0.011 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.4.attn.proj.bias
 |  1.042 |  0.969 |  1.276 |  0.064 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.weight
 |  0.002 | -0.044 |  0.037 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.4.norm2.bias
 | -0.000 | -0.173 |  0.335 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.4.mlp.fc1.weight
 |  0.003 | -0.021 |  0.026 |  0.011 | torch.Size([60]) || layers.1.residual_group.blocks.4.mlp.fc1.bias
 | -0.000 | -0.112 |  0.160 |  0.029 | torch.Size([30, 60]) || layers.1.residual_group.blocks.4.mlp.fc2.weight
 |  0.000 | -0.014 |  0.012 |  0.008 | torch.Size([30]) || layers.1.residual_group.blocks.4.mlp.fc2.bias
 | -12.109 | -100.000 |  0.000 | 32.624 | torch.Size([64, 64, 64]) || layers.1.residual_group.blocks.5.attn_mask
 |  1.103 |  0.981 |  1.370 |  0.107 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.weight
 |  0.002 | -0.036 |  0.039 |  0.020 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm1.bias
 | -0.065 | -1.210 |  2.978 |  0.243 | torch.Size([225, 6]) || layers.1.residual_group.blocks.5.attn.relative_position_bias_table
 | 112.000 |  0.000 | 224.000 | 48.719 | torch.Size([64, 64]) || layers.1.residual_group.blocks.5.attn.relative_position_index
 |  0.002 | -0.905 |  0.866 |  0.182 | torch.Size([90, 30]) || layers.1.residual_group.blocks.5.attn.qkv.weight
 |  0.001 | -0.248 |  0.198 |  0.067 | torch.Size([90]) || layers.1.residual_group.blocks.5.attn.qkv.bias
 |  0.002 | -0.217 |  0.194 |  0.039 | torch.Size([30, 30]) || layers.1.residual_group.blocks.5.attn.proj.weight
 |  0.000 | -0.010 |  0.011 |  0.005 | torch.Size([30]) || layers.1.residual_group.blocks.5.attn.proj.bias
 |  1.043 |  0.979 |  1.275 |  0.071 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.weight
 |  0.004 | -0.037 |  0.047 |  0.023 | torch.Size([30]) || layers.1.residual_group.blocks.5.norm2.bias
 | -0.000 | -0.194 |  0.173 |  0.036 | torch.Size([60, 30]) || layers.1.residual_group.blocks.5.mlp.fc1.weight
 | -0.000 | -0.028 |  0.021 |  0.012 | torch.Size([60]) || layers.1.residual_group.blocks.5.mlp.fc1.bias
 | -0.001 | -0.132 |  0.205 |  0.031 | torch.Size([30, 60]) || layers.1.residual_group.blocks.5.mlp.fc2.weight
 |  0.000 | -0.012 |  0.012 |  0.006 | torch.Size([30]) || layers.1.residual_group.blocks.5.mlp.fc2.bias
 | -0.000 | -0.179 |  0.178 |  0.039 | torch.Size([30, 30, 3, 3]) || layers.1.conv.weight
 |  0.001 | -0.054 |  0.073 |  0.035 | torch.Size([30]) || layers.1.conv.bias
 |  0.990 |  0.872 |  1.330 |  0.079 | torch.Size([30]) || norm.weight
 | -0.000 | -0.120 |  0.097 |  0.039 | torch.Size([30]) || norm.bias
 |  0.000 | -0.215 |  0.229 |  0.039 | torch.Size([30, 30, 3, 3]) || conv_after_body.weight
 |  0.005 | -0.045 |  0.051 |  0.031 | torch.Size([30]) || conv_after_body.bias
 | -0.001 | -0.156 |  0.230 |  0.036 | torch.Size([12, 30, 3, 3]) || upsample.0.weight
 | -0.004 | -0.039 |  0.034 |  0.024 | torch.Size([12]) || upsample.0.bias

22-11-08 17:37:24.983 : <epoch:  1, iter:  25,200, lr:2.000e-04> G_loss: 2.739e-02 
22-11-08 17:42:30.292 : <epoch:  3, iter:  25,400, lr:2.000e-04> G_loss: 2.289e-02 
22-11-08 17:47:33.810 : <epoch:  5, iter:  25,600, lr:2.000e-04> G_loss: 2.623e-02 
22-11-08 17:52:36.294 : <epoch:  7, iter:  25,800, lr:2.000e-04> G_loss: 1.971e-02 
22-11-08 17:57:37.802 : <epoch:  9, iter:  26,000, lr:2.000e-04> G_loss: 2.508e-02 
22-11-08 18:02:27.290 : <epoch: 10, iter:  26,200, lr:2.000e-04> G_loss: 2.810e-02 
22-11-08 18:07:29.579 : <epoch: 12, iter:  26,400, lr:2.000e-04> G_loss: 2.129e-02 
22-11-08 18:12:32.282 : <epoch: 14, iter:  26,600, lr:2.000e-04> G_loss: 2.370e-02 
22-11-08 18:17:34.214 : <epoch: 16, iter:  26,800, lr:2.000e-04> G_loss: 2.825e-02 
22-11-08 18:22:37.498 : <epoch: 18, iter:  27,000, lr:2.000e-04> G_loss: 2.457e-02 
22-11-08 18:27:27.534 : <epoch: 19, iter:  27,200, lr:2.000e-04> G_loss: 2.758e-02 
22-11-08 18:32:31.739 : <epoch: 21, iter:  27,400, lr:2.000e-04> G_loss: 2.115e-02 
22-11-08 18:37:33.193 : <epoch: 23, iter:  27,600, lr:2.000e-04> G_loss: 2.213e-02 
22-11-08 18:42:35.291 : <epoch: 25, iter:  27,800, lr:2.000e-04> G_loss: 1.527e-02 
22-11-08 18:47:38.722 : <epoch: 27, iter:  28,000, lr:2.000e-04> G_loss: 2.124e-02 
22-11-08 18:52:43.187 : <epoch: 29, iter:  28,200, lr:2.000e-04> G_loss: 2.327e-02 
22-11-08 18:57:32.267 : <epoch: 30, iter:  28,400, lr:2.000e-04> G_loss: 2.188e-02 
22-11-08 19:02:37.320 : <epoch: 32, iter:  28,600, lr:2.000e-04> G_loss: 2.621e-02 
22-11-08 19:07:40.359 : <epoch: 34, iter:  28,800, lr:2.000e-04> G_loss: 2.850e-02 
22-11-08 19:12:43.363 : <epoch: 36, iter:  29,000, lr:2.000e-04> G_loss: 2.499e-02 
22-11-08 19:17:45.457 : <epoch: 38, iter:  29,200, lr:2.000e-04> G_loss: 2.662e-02 
22-11-08 19:22:35.593 : <epoch: 39, iter:  29,400, lr:2.000e-04> G_loss: 1.737e-02 
22-11-08 19:27:40.713 : <epoch: 41, iter:  29,600, lr:2.000e-04> G_loss: 1.976e-02 
22-11-08 19:32:42.644 : <epoch: 43, iter:  29,800, lr:2.000e-04> G_loss: 2.631e-02 
22-11-08 19:37:46.322 : <epoch: 45, iter:  30,000, lr:2.000e-04> G_loss: 2.333e-02 
22-11-08 19:37:46.322 : Saving the model.
22-11-08 19:37:50.833 : ---1--> babyx2.png | 37.09dB
22-11-08 19:37:51.249 : ---2--> birdx2.png | 38.90dB
22-11-08 19:37:51.594 : ---3--> butterflyx2.png | 31.34dB
22-11-08 19:37:52.007 : ---4--> headx2.png | 32.09dB
22-11-08 19:37:52.393 : ---5--> womanx2.png | 34.44dB
22-11-08 19:37:52.698 : <epoch: 45, iter:  30,000, Average PSNR : 34.77dB

22-11-08 19:42:50.982 : <epoch: 47, iter:  30,200, lr:2.000e-04> G_loss: 2.433e-02 
22-11-08 19:47:56.510 : <epoch: 49, iter:  30,400, lr:2.000e-04> G_loss: 1.887e-02 
22-11-08 19:52:45.164 : <epoch: 50, iter:  30,600, lr:2.000e-04> G_loss: 2.330e-02 
22-11-08 19:57:47.441 : <epoch: 52, iter:  30,800, lr:2.000e-04> G_loss: 1.940e-02 
22-11-08 20:02:51.544 : <epoch: 54, iter:  31,000, lr:2.000e-04> G_loss: 1.756e-02 
22-11-08 20:07:54.121 : <epoch: 56, iter:  31,200, lr:2.000e-04> G_loss: 1.895e-02 
22-11-08 20:12:55.507 : <epoch: 58, iter:  31,400, lr:2.000e-04> G_loss: 2.399e-02 
22-11-08 20:17:47.976 : <epoch: 59, iter:  31,600, lr:2.000e-04> G_loss: 2.326e-02 
22-11-08 20:22:51.257 : <epoch: 61, iter:  31,800, lr:2.000e-04> G_loss: 2.587e-02 
22-11-08 20:27:53.362 : <epoch: 63, iter:  32,000, lr:2.000e-04> G_loss: 2.331e-02 
22-11-08 20:32:56.291 : <epoch: 65, iter:  32,200, lr:2.000e-04> G_loss: 2.171e-02 
22-11-08 20:38:00.999 : <epoch: 67, iter:  32,400, lr:2.000e-04> G_loss: 2.425e-02 
22-11-08 20:43:05.118 : <epoch: 69, iter:  32,600, lr:2.000e-04> G_loss: 2.706e-02 
22-11-08 20:47:54.330 : <epoch: 70, iter:  32,800, lr:2.000e-04> G_loss: 2.269e-02 
22-11-08 20:52:58.418 : <epoch: 72, iter:  33,000, lr:2.000e-04> G_loss: 2.016e-02 
22-11-08 20:58:01.206 : <epoch: 74, iter:  33,200, lr:2.000e-04> G_loss: 2.641e-02 
22-11-08 21:03:04.046 : <epoch: 76, iter:  33,400, lr:2.000e-04> G_loss: 2.073e-02 
22-11-08 21:08:07.383 : <epoch: 78, iter:  33,600, lr:2.000e-04> G_loss: 1.620e-02 
22-11-08 21:12:59.017 : <epoch: 79, iter:  33,800, lr:2.000e-04> G_loss: 2.684e-02 
22-11-08 21:18:02.449 : <epoch: 81, iter:  34,000, lr:2.000e-04> G_loss: 2.321e-02 
22-11-08 21:23:06.522 : <epoch: 83, iter:  34,200, lr:2.000e-04> G_loss: 2.506e-02 
22-11-08 21:28:08.467 : <epoch: 85, iter:  34,400, lr:2.000e-04> G_loss: 2.212e-02 
22-11-08 21:33:13.525 : <epoch: 87, iter:  34,600, lr:2.000e-04> G_loss: 2.621e-02 
22-11-08 21:38:18.661 : <epoch: 89, iter:  34,800, lr:2.000e-04> G_loss: 2.046e-02 
22-11-08 21:53:13.054 : <epoch: 90, iter:  35,000, lr:2.000e-04> G_loss: 2.069e-02 
22-11-08 23:38:07.562 : Saving the model.
22-11-08 23:38:11.177 : ---1--> babyx2.png | 37.14dB
22-11-08 23:40:37.139 : ---2--> birdx2.png | 39.07dB
22-11-08 23:40:37.420 : ---3--> butterflyx2.png | 31.67dB
22-11-08 23:40:42.721 : ---4--> headx2.png | 32.14dB
